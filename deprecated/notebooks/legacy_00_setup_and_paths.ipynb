{"cells":[{"cell_type":"markdown","id":"8e42e30a","metadata":{"id":"8e42e30a"},"source":["# 00 — Setup & Path-Safe Runtime (Histopathology Cartography)\n","\n","This notebook fixes the most common Colab failure mode: **Google Drive path confusion**.\n","\n","What it does:\n","- mounts Google Drive\n","- reliably resolves `PROJECT_ROOT` (your project folder) even if Colab CWD is `/content`\n","- loads `pipeline_config.yaml`\n","- initializes structured logging + crash-safe state (`checkpoints/_STATE.json`)\n","- installs only **missing** dependencies (no numpy/pandas/torch upgrades)\n","\n","> If your folder is `My Drive > mit > histopathology_202502...`, Colab path is:\n","> `/content/drive/MyDrive/mit/histopathology_202502...`\n"]},{"cell_type":"markdown","id":"094c2705","metadata":{"id":"094c2705"},"source":["<a id=\"A0.0\"></a>\n","### Cell A0.0 — Mount Drive & Resolve PROJECT_ROOT\n","\n","- **Purpose:** Mount Google Drive and auto-detect the folder containing pipeline_config.yaml.\n","- **Inputs:** Env var HISTO_PROJECT_ROOT (optional); /content/drive/MyDrive/mit (default search base)\n","- **Outputs:** PROJECT_ROOT (Path), sys.path updated\n","- **Depends on:** None\n","- **Writes checkpoints:** None (but prints resolved path)\n"]},{"cell_type":"code","execution_count":2,"id":"4dfe4010","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49,"status":"ok","timestamp":1768287146923,"user":{"displayName":"Djamshed Melikov","userId":"05248288490634855674"},"user_tz":420},"id":"4dfe4010","outputId":"b25c2ec1-870b-4b20-dc05-3fc0780bcf10"},"outputs":[{"output_type":"stream","name":"stdout","text":["✅ PROJECT_ROOT = /content/drive/MyDrive/mit/histopathology_202601012\n","sys.path[0] = /content/drive/MyDrive/mit/histopathology_202601012\n"]}],"source":["import os, sys\n","from pathlib import Path\n","\n","IN_COLAB = \"google.colab\" in sys.modules\n","\n","def _mount_drive(mountpoint: str = \"/content/drive\", max_tries: int = 3, timeout_ms: int = 300000) -> bool:\n","    \"\"\"Robust Google Drive mount with retries (Colab).\n","\n","    Returns True if /content/drive/MyDrive becomes available.\n","    \"\"\"\n","    if not IN_COLAB:\n","        return True\n","    try:\n","        from google.colab import drive  # type: ignore\n","    except Exception as e:\n","        print(\"⚠️ google.colab not available:\", repr(e))\n","        return False\n","\n","    import time\n","\n","    mp = Path(mountpoint)\n","    if (mp / \"MyDrive\").exists():\n","        return True\n","\n","    last = None\n","    for t in range(max_tries):\n","        try:\n","            kwargs = {}\n","            if t > 0:\n","                kwargs[\"force_remount\"] = True\n","            # Some Colab versions accept timeout_ms; ignore if not.\n","            kwargs[\"timeout_ms\"] = timeout_ms\n","            try:\n","                drive.mount(mountpoint, **kwargs)\n","            except TypeError:\n","                kwargs.pop(\"timeout_ms\", None)\n","                if kwargs:\n","                    drive.mount(mountpoint, **kwargs)\n","                else:\n","                    drive.mount(mountpoint)\n","\n","            if (mp / \"MyDrive\").exists():\n","                return True\n","        except Exception as e:\n","            last = e\n","            time.sleep(2)\n","\n","    print(\"❌ Google Drive mount failed.\")\n","    print(\"Fixes to try:\")\n","    print(\"  1) Runtime ▸ Restart runtime, then re-run this cell\")\n","    print(\"  2) Run: from google.colab import drive; drive.flush_and_unmount(); drive.mount('/content/drive', force_remount=True)\")\n","    print(\"  3) In your browser, allow third‑party cookies for colab.research.google.com\")\n","    if last is not None:\n","        print(\"Last error:\", repr(last))\n","    return False\n","\n","if IN_COLAB and not _mount_drive():\n","    raise RuntimeError(\"Cannot continue without Google Drive mounted. Fix Drive mount and re-run this cell.\")\n","\n","# Optional hard-set:\n","os.environ[\"HISTO_PROJECT_ROOT\"] = \"/content/drive/MyDrive/mit/histopathology_202601012\"\n","\n","def resolve_project_root() -> Path:\n","    \"\"\"Find the folder that contains pipeline_config.yaml + label_taxonomy.yaml.\"\"\"\n","    ev = os.environ.get(\"HISTO_PROJECT_ROOT\")\n","    if ev:\n","        p = Path(ev).expanduser()\n","        if (p / \"pipeline_config.yaml\").exists() and (p / \"label_taxonomy.yaml\").exists():\n","            return p\n","        raise FileNotFoundError(f\"HISTO_PROJECT_ROOT is set but required files not found in: {p}\")\n","\n","    bases = [\n","        Path(\"/content/drive/MyDrive/mit\"),\n","        Path(\"/content/drive/MyDrive\"),\n","    ]\n","    required = [\"pipeline_config.yaml\", \"label_taxonomy.yaml\"]\n","    candidates = []\n","    for base in bases:\n","        if not base.exists():\n","            continue\n","        for p in base.glob(\"**/pipeline_config.yaml\"):\n","            root = p.parent\n","            if all((root / rf).exists() for rf in required):\n","                candidates.append(root.resolve())\n","        if candidates:\n","            break\n","\n","    candidates = sorted(set(candidates), key=lambda p: p.stat().st_mtime, reverse=True)\n","    if not candidates:\n","        raise FileNotFoundError(\n","            \"Could not locate project root containing pipeline_config.yaml + label_taxonomy.yaml.\\n\"\n","            \"Expected it somewhere under /content/drive/MyDrive/mit/.\\n\"\n","            \"Fix: copy the project folder into Drive, OR set os.environ['HISTO_PROJECT_ROOT'] explicitly.\"\n","        )\n","\n","    if len(candidates) > 1:\n","        print(\"⚠️ Multiple candidate project roots found; using newest. To force, set HISTO_PROJECT_ROOT.\")\n","        for c in candidates[:5]:\n","            print(\"  -\", c)\n","\n","    return candidates[0]\n","\n","PROJECT_ROOT = resolve_project_root().resolve()\n","os.environ[\"HISTO_PROJECT_ROOT\"] = str(PROJECT_ROOT)\n","print(\"✅ PROJECT_ROOT =\", PROJECT_ROOT)\n","\n","if str(PROJECT_ROOT) not in sys.path:\n","    sys.path.insert(0, str(PROJECT_ROOT))\n","\n","print(\"sys.path[0] =\", sys.path[0])\n"]},{"cell_type":"markdown","id":"fd583a23","metadata":{"id":"fd583a23"},"source":["<a id=\"A0.1\"></a>\n","### Cell A0.1 — Load config & init runtime\n","\n","- **Purpose:** Load YAML config and initialize logging, checkpoints, and run STATE.\n","- **Inputs:** PROJECT_ROOT, pipeline_config.yaml\n","- **Outputs:** CFG dict, logger, checkpoints directories, STATE initialized\n","- **Depends on:** A0.0\n","- **Writes checkpoints:** checkpoints/_STATE.json, logs/run.jsonl\n"]},{"cell_type":"code","execution_count":3,"id":"4a7b3dcf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5543,"status":"ok","timestamp":1768287152468,"user":{"displayName":"Djamshed Melikov","userId":"05248288490634855674"},"user_tz":420},"id":"4a7b3dcf","outputId":"93ad0e64-c218-494a-ffb6-11558a6504f9"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:histo_cartography:Logging to: /content/drive/MyDrive/mit/histopathology_202601012/logs/run.jsonl\n","INFO:histo_cartography:Loaded existing STATE for resume mode\n","INFO:histo_cartography:Seeds set to 1337\n","INFO:histo_cartography:✅ A0.1 finished in 0.66s\n"]},{"output_type":"stream","name":"stdout","text":["SAFE_MODE = True | DEBUG_LEVEL = 1\n"]}],"source":["\n","import json\n","from pathlib import Path\n","\n","import yaml  # PyYAML (installed on Colab by default, installed if missing in A1.0)\n","\n","from histo_cartography.runtime import init_runtime, set_seed, health_check, cell_context\n","from histo_cartography.paths import ensure_dirs\n","\n","CONFIG_PATH = PROJECT_ROOT / \"pipeline_config.yaml\"\n","assert CONFIG_PATH.exists(), f\"Missing {CONFIG_PATH}\"\n","\n","with cell_context(\n","    \"A0.1\",\n","    purpose=\"Load pipeline config and initialize runtime state/logging.\",\n","    stage=\"A\",\n","    checkpoint_paths=[str(PROJECT_ROOT / \"checkpoints\" / \"_STATE.json\")],\n","):\n","    cfg = yaml.safe_load(CONFIG_PATH.read_text())\n","    SAFE_MODE = bool(cfg[\"project\"][\"safe_mode\"])\n","    DEBUG_LEVEL = int(cfg[\"project\"][\"debug_level\"])\n","    SEED = int(cfg[\"project\"][\"seed\"])\n","\n","    # Create standard directories on Drive\n","    ensure_dirs(PROJECT_ROOT, [\n","        cfg[\"paths\"][\"log_dir\"],\n","        cfg[\"paths\"][\"checkpoints_dir\"],\n","        cfg[\"paths\"][\"data_raw_dir\"],\n","        cfg[\"paths\"][\"data_staging_dir\"],\n","        cfg[\"paths\"][\"exports_dir\"],\n","        \"exports/eda\",\n","        \"exports/cartography\",\n","        \"exports/kg\",\n","    ])\n","\n","    init_runtime(PROJECT_ROOT, safe_mode=SAFE_MODE, debug_level=DEBUG_LEVEL,\n","                 log_dir_rel=cfg[\"paths\"][\"log_dir\"],\n","                 checkpoint_dir_rel=cfg[\"paths\"][\"checkpoints_dir\"])\n","\n","    set_seed(SEED)\n","\n","print(\"SAFE_MODE =\", SAFE_MODE, \"| DEBUG_LEVEL =\", DEBUG_LEVEL)\n"]},{"cell_type":"markdown","id":"92419510","metadata":{"id":"92419510"},"source":["<a id=\"A1.0\"></a>\n","### Cell A1.0 — Dependency resolver (conservative)\n","\n","- **Purpose:** Install only missing packages. Avoid upgrading numpy/pandas/torch. Optional risky installs behind flag.\n","- **Inputs:** cfg.project.allow_risky_installs\n","- **Outputs:** Installed packages, checkpoints/requirements.lock.txt\n","- **Depends on:** A0.1\n","- **Writes checkpoints:** checkpoints/requirements.lock.txt\n"]},{"cell_type":"code","execution_count":4,"id":"b532640a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8028,"status":"ok","timestamp":1768287160503,"user":{"displayName":"Djamshed Melikov","userId":"05248288490634855674"},"user_tz":420},"id":"b532640a","outputId":"791ffc3d-a28a-4b99-8dda-cf5aa6d83191"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:histo_cartography:▶️  A1.0: Install missing dependencies conservatively\n"]},{"output_type":"stream","name":"stdout","text":["Installing: ['rdflib']\n","⚠️  Risky deps disabled. UMAP/HDBSCAN will fallback to PCA/KMeans unless you set allow_risky_installs=true.\n","pip check failed (non-fatal): Command '['/usr/bin/python3', '-m', 'pip', 'check']' returned non-zero exit status 1.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:histo_cartography:✅ A1.0 finished in 8.00s\n"]},{"output_type":"stream","name":"stdout","text":["✅ requirements.lock.txt written to: /content/drive/MyDrive/mit/histopathology_202601012/checkpoints/requirements.lock.txt\n"]}],"source":["\n","import importlib.util\n","import subprocess, sys\n","from pathlib import Path\n","import yaml\n","\n","from histo_cartography.runtime import cell_context\n","\n","cfg = yaml.safe_load((PROJECT_ROOT / \"pipeline_config.yaml\").read_text())\n","ALLOW_RISKY = bool(cfg[\"project\"].get(\"allow_risky_installs\", False))\n","\n","# Conservative required deps\n","REQUIRED = [\n","    \"pyarrow\",   # parquet\n","    \"rdflib\",    # RDF export (pure python)\n","    \"tqdm\",      # progress bars\n","]\n","\n","# Optional / riskier deps (compiled extensions). Only install when ALLOW_RISKY=True.\n","RISKY = [\n","    \"umap-learn\",  # may pull numba/llvmlite\n","    \"hdbscan\",     # compiled\n","]\n","\n","def spec_exists(pkg: str) -> bool:\n","    # pkg names like \"umap-learn\" map to module \"umap\"; we'll check common transforms.\n","    candidates = [pkg, pkg.replace(\"-\", \"_\")]\n","    if pkg == \"umap-learn\":\n","        candidates = [\"umap\"]\n","    for m in candidates:\n","        if importlib.util.find_spec(m) is not None:\n","            return True\n","    return False\n","\n","def pip_install(pkgs):\n","    if not pkgs:\n","        return\n","    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + pkgs\n","    print(\"Installing:\", pkgs)\n","    subprocess.check_call(cmd)\n","\n","with cell_context(\"A1.0\", purpose=\"Install missing dependencies conservatively\", stage=\"A\"):\n","    missing = [p for p in REQUIRED if not spec_exists(p)]\n","    pip_install(missing)\n","\n","    if ALLOW_RISKY:\n","        missing_risky = [p for p in RISKY if not spec_exists(p)]\n","        pip_install(missing_risky)\n","    else:\n","        print(\"⚠️  Risky deps disabled. UMAP/HDBSCAN will fallback to PCA/KMeans unless you set allow_risky_installs=true.\")\n","\n","    # pip check (non-fatal)\n","    try:\n","        out = subprocess.check_output([sys.executable, \"-m\", \"pip\", \"check\"], stderr=subprocess.STDOUT).decode()\n","        print(out[:2000])\n","    except Exception as e:\n","        print(\"pip check failed (non-fatal):\", e)\n","\n","    # Lock file\n","    lock_path = PROJECT_ROOT / cfg[\"paths\"][\"checkpoints_dir\"] / \"requirements.lock.txt\"\n","    freeze = subprocess.check_output([sys.executable, \"-m\", \"pip\", \"freeze\"]).decode(\"utf-8\")\n","    lock_path.write_text(freeze)\n","\n","print(\"✅ requirements.lock.txt written to:\", lock_path)\n"]},{"cell_type":"markdown","id":"57cd87db","metadata":{"id":"57cd87db"},"source":["<a id=\"A2.0\"></a>\n","### Cell A2.0 — Binary compatibility guard\n","\n","- **Purpose:** Heuristic checks for common Colab binary incompatibilities (numpy/pandas/torch/CUDA).\n","- **Inputs:** Current environment\n","- **Outputs:** Guard report dict\n","- **Depends on:** A1.0\n","- **Writes checkpoints:** logs/run.jsonl\n"]},{"cell_type":"code","execution_count":5,"id":"9b01fb69","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2612,"status":"ok","timestamp":1768287163120,"user":{"displayName":"Djamshed Melikov","userId":"05248288490634855674"},"user_tz":420},"id":"9b01fb69","outputId":"e22854b0-a19e-4a45-818e-c8412d0fa606"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:histo_cartography:▶️  A2.0: Run binary compatibility guard\n","INFO:histo_cartography:Binary compatibility guard report\n","INFO:histo_cartography:✅ A2.0 finished in 2.55s\n"]},{"output_type":"stream","name":"stdout","text":["Warnings: []\n"]}],"source":["\n","from histo_cartography.runtime import cell_context, binary_compatibility_guard\n","\n","with cell_context(\"A2.0\", purpose=\"Run binary compatibility guard\", stage=\"A\"):\n","    report = binary_compatibility_guard()\n","\n","print(\"Warnings:\", report.get(\"warnings\", []))\n"]},{"cell_type":"markdown","id":"f871fd39","metadata":{"id":"f871fd39"},"source":["<a id=\"A3.0\"></a>\n","### Cell A3.0 — Crash mitigation utilities\n","\n","- **Purpose:** Seed control, torch CUDA memory knobs, and a lightweight watchdog you can call before heavy steps.\n","- **Inputs:** SAFE_MODE, DEBUG_LEVEL, SEED\n","- **Outputs:** watchdog_report() utility\n","- **Depends on:** A0.1\n","- **Writes checkpoints:** None\n"]},{"cell_type":"code","execution_count":6,"id":"4f500cc6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":148,"status":"ok","timestamp":1768287163270,"user":{"displayName":"Djamshed Melikov","userId":"05248288490634855674"},"user_tz":420},"id":"4f500cc6","outputId":"21e9c5f3-0b8d-4a17-d93f-25300986d38e"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:histo_cartography:▶️  A3.0: Configure conservative runtime settings\n","INFO:histo_cartography:✅ A3.0 finished in 0.05s\n"]},{"output_type":"stream","name":"stdout","text":["Runtime fingerprint: {'python': '3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]', 'platform': 'Linux-6.6.105+-x86_64-with-glibc2.35', 'executable': '/usr/bin/python3', 'time_utc': '2026-01-13T06:52:43Z', 'torch': '2.9.0+cpu', 'cuda_available': False, 'cuda_version': None, 'cudnn': None, 'numpy': '2.0.2', 'pandas': '2.2.2', 'sklearn': '1.6.1'}\n","Watchdog report: {'project_root': '/content/drive/MyDrive/mit/histopathology_202601012', 'disk_free_gb': 194.31491088867188, 'cuda_available': False}\n"]}],"source":["\n","import os, sys\n","from histo_cartography.runtime import cell_context, env_fingerprint\n","\n","with cell_context(\"A3.0\", purpose=\"Configure conservative runtime settings\", stage=\"A\"):\n","    os.environ.setdefault(\"PYTHONHASHSEED\", \"0\")\n","    # Torch GPU memory fragmentation mitigations (no effect if CPU-only)\n","    os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"max_split_size_mb:128\")\n","\n","    try:\n","        import torch\n","        torch.backends.cudnn.benchmark = False\n","        torch.backends.cudnn.deterministic = True\n","    except Exception:\n","        pass\n","\n","    fp = env_fingerprint()\n","\n","def watchdog_report():\n","    from histo_cartography.runtime import disk_free_gb\n","    from pathlib import Path\n","    rep = {\n","        \"project_root\": str(PROJECT_ROOT),\n","        \"disk_free_gb\": float(disk_free_gb(Path(PROJECT_ROOT))),\n","    }\n","    try:\n","        import torch\n","        rep[\"cuda_available\"] = bool(torch.cuda.is_available())\n","        if torch.cuda.is_available():\n","            rep[\"gpu_name\"] = torch.cuda.get_device_name(0)\n","            rep[\"gpu_mem_allocated_mb\"] = int(torch.cuda.memory_allocated() / (1024**2))\n","    except Exception:\n","        pass\n","    return rep\n","\n","print(\"Runtime fingerprint:\", fp)\n","print(\"Watchdog report:\", watchdog_report())\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":5}