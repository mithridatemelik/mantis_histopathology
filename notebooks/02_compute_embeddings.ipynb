{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44cd5ccf",
   "metadata": {},
   "source": [
    "# Stage 02 — Compute embeddings (parquet-first, visual-first)\n",
    "\n",
    "This notebook reads **Stage 01** `exports/stage_01_prepare/items.parquet`, computes **hybrid embeddings** (image + optional morphology/text), fuses them into a single vector per item, and writes:\n",
    "\n",
    "- `exports/stage_02_embeddings/items_with_embeddings.parquet`\n",
    "- plus intermediate parquet artifacts: `image_embeddings.parquet`, `morph_features.parquet`, `morph_embeddings.parquet`, `text_embeddings.parquet` (if enabled), `fused_embeddings.parquet`\n",
    "\n",
    "**New in this refactor**\n",
    "- **PEEP/POST** health gates (critic checks)\n",
    "- **Visual-first**: key plots are shown inline *and* saved to `exports/stage_02_embeddings/plots/`\n",
    "- `viz_index.parquet` is written for easy browsing of plots per stage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c8aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Colab-first setup (safe defaults) ---\n",
    "import os, sys, time\n",
    "from pathlib import Path\n",
    "\n",
    "# Notebook toggles (edit as needed)\n",
    "FORCE_REBUILD = False        # recompute stage outputs even if parquet exists\n",
    "FAST_MODE = True             # smaller samples / cheaper diagnostics\n",
    "EDA_LEVEL = \"core\"           # \"core\" | \"standard\" | \"deep\"\n",
    "SHOW_PLOTS = True            # always True for this repo\n",
    "SAVE_PLOTS = True            # always True for this repo\n",
    "\n",
    "DRIVE_SEARCH_BASE = \"/content/drive/MyDrive\"  # adjust if needed\n",
    "\n",
    "def _is_colab() -> bool:\n",
    "    return \"google.colab\" in sys.modules\n",
    "\n",
    "if _is_colab():\n",
    "    from google.colab import drive  # type: ignore\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "def _resolve_project_root() -> Path:\n",
    "    # 1) explicit override\n",
    "    ev = os.environ.get(\"HISTO_PROJECT_ROOT\")\n",
    "    if ev and Path(ev).exists():\n",
    "        return Path(ev)\n",
    "\n",
    "    # 2) search on Drive (best effort)\n",
    "    base = Path(DRIVE_SEARCH_BASE)\n",
    "    candidates = []\n",
    "    if base.exists():\n",
    "        for p in base.glob(\"**/pipeline_config.yaml\"):\n",
    "            parent = p.parent\n",
    "            if (parent / \"label_taxonomy.yaml\").exists():\n",
    "                candidates.append(parent)\n",
    "    if candidates:\n",
    "        candidates = sorted(candidates, key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "        return candidates[0]\n",
    "\n",
    "    # 3) local fallback: walk up from CWD\n",
    "    p = Path.cwd()\n",
    "    for _ in range(10):\n",
    "        if (p / \"pipeline_config.yaml\").exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "\n",
    "    raise FileNotFoundError(\"Could not resolve PROJECT_ROOT. Set HISTO_PROJECT_ROOT env var.\")\n",
    "\n",
    "PROJECT_ROOT = _resolve_project_root()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "\n",
    "# Install deps (fast, uses requirements.txt)\n",
    "import subprocess\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", \"-r\", str(PROJECT_ROOT / \"requirements.txt\")])\n",
    "\n",
    "# Optional extras\n",
    "if EDA_LEVEL in (\"standard\", \"deep\"):\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", \"umap-learn\"])\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ optional install failed (umap-learn):\", e)\n",
    "\n",
    "if EDA_LEVEL == \"deep\":\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", \"ydata-profiling\"])\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ optional install failed (ydata-profiling):\", e)\n",
    "\n",
    "import yaml\n",
    "cfg = yaml.safe_load((PROJECT_ROOT / \"pipeline_config.yaml\").read_text())\n",
    "\n",
    "EXPORTS_DIR = PROJECT_ROOT / str(cfg.get(\"paths\", {}).get(\"exports_dir\", \"exports\"))\n",
    "EXPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SAFE_MODE = bool(cfg.get(\"project\", {}).get(\"safe_mode\", True))\n",
    "SEED = int(cfg.get(\"project\", {}).get(\"seed\", 1337))\n",
    "\n",
    "print(\"SAFE_MODE:\", SAFE_MODE, \"| EDA_LEVEL:\", EDA_LEVEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa546d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Stage paths + registries ---\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from histo_cartography.viz import ensure_dir\n",
    "from histo_cartography.artifact_registry import register_artifact, append_stage_manifest\n",
    "from histo_cartography.critic import run_critic, write_critic_report, critic_result_table, critic_issues_table\n",
    "\n",
    "stage_in = EXPORTS_DIR / \"stage_01_prepare\" / \"items.parquet\"\n",
    "assert stage_in.exists(), f\"missing upstream parquet: {stage_in}\"\n",
    "\n",
    "stage_dir = EXPORTS_DIR / \"stage_02_embeddings\"\n",
    "plots_dir = ensure_dir(stage_dir / \"plots\")\n",
    "qa_dir = ensure_dir(stage_dir / \"qa\")\n",
    "eda_dir = ensure_dir(stage_dir / \"eda\")\n",
    "\n",
    "out_items_path = stage_dir / \"items_with_embeddings.parquet\"\n",
    "\n",
    "viz_records = []  # appended throughout the notebook\n",
    "\n",
    "print(\"stage_in:\", stage_in)\n",
    "print(\"stage_dir:\", stage_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e6e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PEEP: load upstream items (Stage 01) ---\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "items = pd.read_parquet(stage_in)\n",
    "display(items.head(3))\n",
    "print(\"items shape:\", items.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f988579",
   "metadata": {},
   "source": [
    "## PEEP — Preflight health + EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acd63e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEEP (1/4) — Overview table (schema / missingness / examples)\n",
    "from IPython.display import display\n",
    "from histo_cartography.eda_reports import df_overview_table\n",
    "\n",
    "display(df_overview_table(items, max_cols=40).head(40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffdafda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEEP (2/4) — Missingness plot (top columns)\n",
    "from histo_cartography.eda_reports import plot_missingness\n",
    "from histo_cartography.viz import save_and_display, register_plot\n",
    "\n",
    "fig = plot_missingness(items, top_k=25, title=\"Stage 02 PEEP: items missingness (top 25)\")\n",
    "out_path = plots_dir / \"peep_missingness_top25.png\"\n",
    "save_and_display(fig, out_path)\n",
    "\n",
    "register_plot(\n",
    "    viz_records,\n",
    "    stage=\"stage_02_embeddings\",\n",
    "    plot_id=\"peep_missingness_top25\",\n",
    "    title=\"PEEP missingness (top 25 columns)\",\n",
    "    path=out_path,\n",
    "    tags=[\"peep\", \"missingness\"],\n",
    "    is_core=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc810fe",
   "metadata": {},
   "source": [
    "**Interpretation**: Large missingness in required columns (e.g., `image_path`, `label`) usually indicates a broken ingest or an incomplete staging step.\n",
    "\n",
    "**Warning signs**: `image_path` missingness > 0, or `item_id` duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf90d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEEP (3/4) — Dataset/source distribution (bar)\n",
    "import matplotlib.pyplot as plt\n",
    "from histo_cartography.viz import save_and_display, register_plot\n",
    "\n",
    "vc = items[\"source\"].astype(str).value_counts().head(30)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "plt.bar(vc.index.astype(str), vc.values)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Stage 02 PEEP: source/dataset distribution (top 30)\")\n",
    "plt.ylabel(\"n items\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = plots_dir / \"peep_source_distribution_top30.png\"\n",
    "save_and_display(fig, out_path)\n",
    "\n",
    "register_plot(\n",
    "    viz_records,\n",
    "    stage=\"stage_02_embeddings\",\n",
    "    plot_id=\"peep_source_distribution_top30\",\n",
    "    title=\"PEEP source/dataset distribution (top 30)\",\n",
    "    path=out_path,\n",
    "    tags=[\"peep\", \"distribution\", \"dataset\"],\n",
    "    is_core=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb703d8",
   "metadata": {},
   "source": [
    "**Interpretation**: In SAFE_MODE you may only see a subset. In full mode, this should reflect all enabled datasets.\n",
    "\n",
    "**Warning signs**: Only one dataset shows up when multiple were expected; or extremely imbalanced datasets leading to dataset islands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df4fae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEEP (4/4) — Critic hard/soft gates (items)\n",
    "from IPython.display import display\n",
    "\n",
    "critic_items = run_critic(\n",
    "    df=items,\n",
    "    stage=\"stage_02_embeddings\",\n",
    "    gate=\"peep_items\",\n",
    "    required_cols=[\"item_id\",\"source\",\"split\",\"label\",\"text\",\"image_path\",\"width\",\"height\",\"mpp\"],\n",
    "    id_col=\"item_id\",\n",
    "    min_rows=100 if not SAFE_MODE else 10,\n",
    "    key_nonnull_cols=[\"item_id\",\"image_path\"],\n",
    ")\n",
    "\n",
    "write_critic_report(critic_items, qa_dir / \"critic_peep_items.json\")\n",
    "display(critic_result_table(critic_items))\n",
    "display(critic_issues_table(critic_items).head(50))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aafcce",
   "metadata": {},
   "source": [
    "## Stage logic — Compute + fuse embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51404738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main stage logic: compute embeddings (idempotent) ---\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from histo_cartography.exports import save_parquet\n",
    "from histo_cartography import embeddings as emb\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# config\n",
    "emb_cfg = cfg.get(\"embeddings\", {})\n",
    "img_cfg = emb_cfg.get(\"image\", {})\n",
    "txt_cfg = emb_cfg.get(\"text\", {})\n",
    "morph_cfg = emb_cfg.get(\"morphology\", {})\n",
    "fusion_cfg = emb_cfg.get(\"fusion\", {})\n",
    "\n",
    "batch_size = int(img_cfg.get(\"batch_size_safe\", 64) if SAFE_MODE else img_cfg.get(\"batch_size_full\", 256))\n",
    "target_dim = int(fusion_cfg.get(\"target_dim\", 256))\n",
    "use_text_modality = bool(txt_cfg.get(\"use_text_modality\", False))\n",
    "\n",
    "if out_items_path.exists() and not FORCE_REBUILD:\n",
    "    items_with_embeddings = pd.read_parquet(out_items_path)\n",
    "    print(f\"✅ Loaded existing items_with_embeddings.parquet: {items_with_embeddings.shape}\")\n",
    "else:\n",
    "    # 1) image embeddings\n",
    "    img_emb = emb.embed_images_resnet50(\n",
    "        items,\n",
    "        image_col=\"image_path\",\n",
    "        batch_size=batch_size,\n",
    "        device=None,\n",
    "        max_items=None,  # stage 01 already sampled in SAFE_MODE\n",
    "    )\n",
    "    save_parquet(img_emb, stage_dir / \"image_embeddings.parquet\")\n",
    "\n",
    "    emb_dfs = [img_emb]\n",
    "\n",
    "    # 2) morphology embeddings (best effort)\n",
    "    try:\n",
    "        morph_feats = emb.compute_morphology_features(items, image_col=\"image_path\")\n",
    "        save_parquet(morph_feats, stage_dir / \"morph_features.parquet\")\n",
    "        morph_emb = emb.embed_morphology_features(morph_feats)\n",
    "        save_parquet(morph_emb, stage_dir / \"morph_embeddings.parquet\")\n",
    "        emb_dfs.append(morph_emb)\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ morphology embedding skipped:\", e)\n",
    "\n",
    "    # 3) text embeddings (optional; default off to avoid label leakage)\n",
    "    if use_text_modality:\n",
    "        txt_emb = emb.embed_text_tfidf_svd(\n",
    "            items,\n",
    "            text_col=\"text\",\n",
    "            max_features=int(txt_cfg.get(\"max_features\", 8192)),\n",
    "            svd_dim=int(txt_cfg.get(\"svd_dim\", 128)),\n",
    "        )\n",
    "        save_parquet(txt_emb, stage_dir / \"text_embeddings.parquet\")\n",
    "        emb_dfs.append(txt_emb)\n",
    "    else:\n",
    "        print(\"text modality disabled (recommended default)\")\n",
    "\n",
    "    # 4) fuse -> one vector per item\n",
    "    if len(emb_dfs) == 1:\n",
    "        fused = emb_dfs[0][[\"item_id\", \"model_id\", \"dim\", \"vector\"]].copy()\n",
    "        fused[\"model_id\"] = fused[\"model_id\"].astype(str) + \"|single\"\n",
    "    else:\n",
    "        fused = emb.fuse_embeddings_concat_pca(emb_dfs, target_dim=target_dim)\n",
    "\n",
    "    save_parquet(fused, stage_dir / \"fused_embeddings.parquet\")\n",
    "\n",
    "    # 5) join back to items\n",
    "    items_with_embeddings = items.merge(fused, on=\"item_id\", how=\"inner\")\n",
    "    assert len(items_with_embeddings) == len(items), \"embedding join dropped rows\"\n",
    "\n",
    "    save_parquet(items_with_embeddings, out_items_path)\n",
    "\n",
    "runtime_sec = time.time() - t0\n",
    "print(\"runtime_sec:\", round(runtime_sec, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6262c5",
   "metadata": {},
   "source": [
    "## CHECKPOINT — After embedding fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb1ce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKPOINT: critic gates on items_with_embeddings\n",
    "from IPython.display import display\n",
    "\n",
    "critic_out = run_critic(\n",
    "    df=items_with_embeddings,\n",
    "    stage=\"stage_02_embeddings\",\n",
    "    gate=\"checkpoint_items_with_embeddings\",\n",
    "    required_cols=[\"item_id\",\"source\",\"label\",\"image_path\",\"vector\",\"dim\"],\n",
    "    id_col=\"item_id\",\n",
    "    min_rows=100 if not SAFE_MODE else 10,\n",
    "    key_nonnull_cols=[\"item_id\",\"image_path\",\"vector\"],\n",
    "    vector_col=\"vector\",\n",
    ")\n",
    "\n",
    "write_critic_report(critic_out, qa_dir / \"critic_checkpoint_items_with_embeddings.json\")\n",
    "display(critic_result_table(critic_out))\n",
    "display(critic_issues_table(critic_out).head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1b7ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register stage artifacts in manifest (parquet-first DAG wiring)\n",
    "schema_version = str(cfg.get(\"project\", {}).get(\"schema_version\", \"0.1.0\"))\n",
    "\n",
    "# Artifact-level registry (keeps backward compatibility)\n",
    "register_artifact(\n",
    "    project_root=PROJECT_ROOT,\n",
    "    stage=\"stage_02_embeddings\",\n",
    "    artifact=\"items_with_embeddings\",\n",
    "    path=out_items_path,\n",
    "    schema_version=schema_version,\n",
    "    inputs=[stage_in],\n",
    "    df=items_with_embeddings,\n",
    "    warnings_count=int(critic_out.warnings_count),\n",
    "    fails_count=int(critic_out.fails_count),\n",
    "    runtime_sec=float(runtime_sec),\n",
    "    notes=\"items + fused embedding vector\",\n",
    ")\n",
    "\n",
    "# Stage-run summary row\n",
    "append_stage_manifest(\n",
    "    project_root=PROJECT_ROOT,\n",
    "    stage=\"stage_02_embeddings\",\n",
    "    inputs=[stage_in],\n",
    "    outputs=[out_items_path],\n",
    "    schema_version=schema_version,\n",
    "    warnings_count=int(critic_out.warnings_count),\n",
    "    fails_count=int(critic_out.fails_count),\n",
    "    runtime_sec=float(runtime_sec),\n",
    "    notes=\"stage 02 run summary\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f569ca",
   "metadata": {},
   "source": [
    "## POST — Postflight health + EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df374d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST (1/3) — Overview table (items_with_embeddings)\n",
    "from IPython.display import display\n",
    "from histo_cartography.eda_reports import df_overview_table\n",
    "\n",
    "display(df_overview_table(items_with_embeddings, max_cols=40).head(40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad944006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST (2/3) — Missingness plot (items_with_embeddings)\n",
    "from histo_cartography.eda_reports import plot_missingness\n",
    "from histo_cartography.viz import save_and_display, register_plot\n",
    "\n",
    "fig = plot_missingness(items_with_embeddings, top_k=25, title=\"Stage 02 POST: items_with_embeddings missingness (top 25)\")\n",
    "out_path = plots_dir / \"post_missingness_top25.png\"\n",
    "save_and_display(fig, out_path)\n",
    "\n",
    "register_plot(\n",
    "    viz_records,\n",
    "    stage=\"stage_02_embeddings\",\n",
    "    plot_id=\"post_missingness_top25\",\n",
    "    title=\"POST missingness (top 25 columns)\",\n",
    "    path=out_path,\n",
    "    tags=[\"post\", \"missingness\"],\n",
    "    is_core=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779cb4e9",
   "metadata": {},
   "source": [
    "**Interpretation**: After fusion, `vector` should be present for every row.\n",
    "\n",
    "**Warning signs**: Any null vectors or inconsistent `dim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdc52e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST (3/3) — Critic summary (should match checkpoint)\n",
    "from IPython.display import display\n",
    "\n",
    "display(critic_result_table(critic_out))\n",
    "display(critic_issues_table(critic_out).head(50))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becc796b",
   "metadata": {},
   "source": [
    "## Core embedding diagnostics (one plot per cell)\n",
    "These are the most important plots for cluster quality downstream (Stage 03+)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c89c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core plot 1 — Embedding norm histogram\n",
    "from histo_cartography.eda_reports import plot_embedding_norms\n",
    "from histo_cartography.viz import save_and_display, register_plot\n",
    "\n",
    "emb_df = items_with_embeddings[[\"item_id\",\"vector\"]].copy()\n",
    "\n",
    "fig = plot_embedding_norms(emb_df, vector_col=\"vector\", title=\"Embedding norm histogram (fused)\")\n",
    "out_path = plots_dir / \"embedding_norm_hist.png\"\n",
    "save_and_display(fig, out_path)\n",
    "\n",
    "register_plot(\n",
    "    viz_records,\n",
    "    stage=\"stage_02_embeddings\",\n",
    "    plot_id=\"embedding_norm_hist\",\n",
    "    title=\"Embedding norm histogram (fused)\",\n",
    "    path=out_path,\n",
    "    tags=[\"core\", \"embeddings\", \"norms\"],\n",
    "    is_core=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016652fa",
   "metadata": {},
   "source": [
    "**Interpretation**: Norms should not collapse to a single value.\n",
    "\n",
    "**Warning signs**: Extremely narrow distribution (collapsed embeddings) or heavy spikes at 0 (bad vectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e592d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Core plot 2 — PCA explained variance curve (cumulative)\n",
    "from histo_cartography.eda_reports import plot_pca_explained_variance\n",
    "from histo_cartography.viz import save_and_display, register_plot\n",
    "from histo_cartography.stats_tests import effective_rank\n",
    "import numpy as np\n",
    "\n",
    "fig, meta = plot_pca_explained_variance(emb_df, vector_col=\"vector\", n_components=50, title=\"PCA cumulative explained variance (fused)\")\n",
    "out_path = plots_dir / \"pca_explained_variance_cumsum.png\"\n",
    "save_and_display(fig, out_path)\n",
    "\n",
    "# effective rank from singular values approximation\n",
    "try:\n",
    "    # Convert explained variance ratio -> approximate singular value weights\n",
    "    evr = np.asarray(meta.get(\"explained_variance_ratio\", []), dtype=float)\n",
    "    er = effective_rank(np.sqrt(np.maximum(evr, 0)))\n",
    "except Exception:\n",
    "    er = None\n",
    "\n",
    "(meta_path := qa_dir / \"pca_meta.json\").write_text(json.dumps({**meta, \"effective_rank_approx\": er}, indent=2))\n",
    "\n",
    "register_plot(\n",
    "    viz_records,\n",
    "    stage=\"stage_02_embeddings\",\n",
    "    plot_id=\"pca_explained_variance_cumsum\",\n",
    "    title=\"PCA cumulative explained variance (fused)\",\n",
    "    path=out_path,\n",
    "    tags=[\"core\", \"embeddings\", \"pca\"],\n",
    "    is_core=True,\n",
    "    notes=f\"effective_rank_approx={er}\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2569f583",
   "metadata": {},
   "source": [
    "**Interpretation**: If a tiny number of components explain almost all variance, embeddings may be low-rank or collapsed.\n",
    "\n",
    "**Warning signs**: Effective rank extremely small relative to embedding dim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5057b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core plot 3 — Pairwise cosine similarity distribution (sampled)\n",
    "from histo_cartography.eda_reports import plot_cosine_similarity_distribution\n",
    "from histo_cartography.viz import save_and_display, register_plot\n",
    "\n",
    "fig, meta = plot_cosine_similarity_distribution(emb_df, vector_col=\"vector\", sample_pairs=2000, title=\"Pairwise cosine similarity (sampled, fused)\")\n",
    "out_path = plots_dir / \"cosine_similarity_distribution.png\"\n",
    "save_and_display(fig, out_path)\n",
    "\n",
    "(qa_dir / \"cosine_similarity_meta.json\").write_text(json.dumps(meta, indent=2))\n",
    "\n",
    "register_plot(\n",
    "    viz_records,\n",
    "    stage=\"stage_02_embeddings\",\n",
    "    plot_id=\"cosine_similarity_distribution\",\n",
    "    title=\"Pairwise cosine similarity distribution (sampled)\",\n",
    "    path=out_path,\n",
    "    tags=[\"core\", \"embeddings\", \"similarity\"],\n",
    "    is_core=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e53ec9",
   "metadata": {},
   "source": [
    "**Interpretation**: Similarity distribution should be broad enough to allow clustering.\n",
    "\n",
    "**Warning signs**: Nearly all pairs have very high similarity (collapsed) or near-zero similarity (no structure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934b8bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core plot 4 — 2D map (UMAP/PCA) colored by dataset/source\n",
    "from histo_cartography.eda_reports import compute_umap_2d, plot_category_scatter_2d\n",
    "from histo_cartography.viz import save_and_display, register_plot\n",
    "\n",
    "xy, meta = compute_umap_2d(items_with_embeddings, vector_col=\"vector\", sample_n=3000 if FAST_MODE else 8000, random_state=SEED)\n",
    "cats = items_with_embeddings.iloc[xy[\"sample_idx\"].tolist()][\"source\"].astype(str).tolist()\n",
    "\n",
    "fig = plot_category_scatter_2d(xy, cats, title=f\"2D map colored by dataset/source ({meta['method']})\", max_legend=20)\n",
    "out_path = plots_dir / \"map2d_by_source.png\"\n",
    "save_and_display(fig, out_path)\n",
    "\n",
    "(qa_dir / \"map2d_meta_source.json\").write_text(json.dumps(meta, indent=2))\n",
    "register_plot(\n",
    "    viz_records,\n",
    "    stage=\"stage_02_embeddings\",\n",
    "    plot_id=\"map2d_by_source\",\n",
    "    title=\"2D map colored by dataset/source\",\n",
    "    path=out_path,\n",
    "    tags=[\"core\", \"embeddings\", \"umap\", \"dataset\"],\n",
    "    is_core=True,\n",
    "    notes=f\"method={meta.get('method')}\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac42a28a",
   "metadata": {},
   "source": [
    "**Interpretation**: Ideally, structure is driven by morphology, not dataset.\n",
    "\n",
    "**Warning signs**: Strong dataset islands → potential domain shift or leakage (e.g., different stain/scan artifacts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828b66a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core plot 5 — 2D map (UMAP/PCA) colored by tissue label\n",
    "from histo_cartography.eda_reports import plot_category_scatter_2d\n",
    "from histo_cartography.viz import save_and_display, register_plot\n",
    "\n",
    "cats = items_with_embeddings.iloc[xy[\"sample_idx\"].tolist()][\"label\"].astype(str).tolist()\n",
    "\n",
    "fig = plot_category_scatter_2d(xy, cats, title=f\"2D map colored by tissue label ({meta['method']})\", max_legend=25)\n",
    "out_path = plots_dir / \"map2d_by_label.png\"\n",
    "save_and_display(fig, out_path)\n",
    "\n",
    "register_plot(\n",
    "    viz_records,\n",
    "    stage=\"stage_02_embeddings\",\n",
    "    plot_id=\"map2d_by_label\",\n",
    "    title=\"2D map colored by tissue label\",\n",
    "    path=out_path,\n",
    "    tags=[\"core\", \"embeddings\", \"umap\", \"label\"],\n",
    "    is_core=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ec6473",
   "metadata": {},
   "source": [
    "**Interpretation**: Labels (if meaningful) should show local coherence, but not perfect separation.\n",
    "\n",
    "**Warning signs**: Perfect separation may indicate leakage; no separation may indicate embeddings not capturing tissue structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f05536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core diagnostic 6A — Dataset separability probe (table)\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# build sample\n",
    "X = np.asarray(items_with_embeddings[\"vector\"].tolist(), dtype=np.float32)\n",
    "y = items_with_embeddings[\"source\"].astype(str).to_numpy()\n",
    "\n",
    "# small subsample for speed\n",
    "n = min(len(X), 5000 if FAST_MODE else 20000)\n",
    "idx = np.random.default_rng(SEED).choice(len(X), size=n, replace=False)\n",
    "Xs = X[idx]\n",
    "ys = y[idx]\n",
    "\n",
    "Xtr, Xte, ytr, yte = train_test_split(Xs, ys, test_size=0.25, random_state=SEED, stratify=ys if len(set(ys))>1 else None)\n",
    "\n",
    "clf = LogisticRegression(max_iter=500, n_jobs=None)\n",
    "clf.fit(Xtr, ytr)\n",
    "pred = clf.predict(Xte)\n",
    "acc = accuracy_score(yte, pred)\n",
    "\n",
    "tab = pd.DataFrame([{\"metric\":\"accuracy\",\"value\":float(acc),\"n_train\":len(Xtr),\"n_test\":len(Xte)}])\n",
    "display(tab)\n",
    "\n",
    "(qa_dir / \"dataset_separability.json\").write_text(json.dumps(tab.to_dict(orient=\"records\")[0], indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb63d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core diagnostic 6B — Dataset separability confusion matrix (plot)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labels = sorted(list(set(yte)))\n",
    "cm = confusion_matrix(yte, pred, labels=labels)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 5))\n",
    "plt.imshow(cm, aspect=\"auto\")\n",
    "plt.colorbar(label=\"count\")\n",
    "plt.xticks(range(len(labels)), labels, rotation=45, ha=\"right\")\n",
    "plt.yticks(range(len(labels)), labels)\n",
    "plt.title(\"Dataset separability (confusion matrix)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = plots_dir / \"dataset_separability_confusion.png\"\n",
    "save_and_display(fig, out_path)\n",
    "\n",
    "register_plot(\n",
    "    viz_records,\n",
    "    stage=\"stage_02_embeddings\",\n",
    "    plot_id=\"dataset_separability_confusion\",\n",
    "    title=\"Dataset separability confusion matrix\",\n",
    "    path=out_path,\n",
    "    tags=[\"core\", \"embeddings\", \"dataset\", \"separability\"],\n",
    "    is_core=True,\n",
    "    notes=f\"accuracy={float(acc):.3f}\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0da5dde",
   "metadata": {},
   "source": [
    "**Interpretation**: If dataset is *too* predictable from embeddings, clustering may reflect dataset artifacts.\n",
    "\n",
    "**Warning signs**: Very high accuracy → domain shift; consider stain normalization, domain adaptation, or rebalancing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b515c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core diagnostic 7A — Drift test across datasets (KS test on embedding norms)\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "from histo_cartography.stats_tests import ks_2samp\n",
    "\n",
    "# norms\n",
    "X = np.asarray(items_with_embeddings[\"vector\"].tolist(), dtype=np.float32)\n",
    "norms = np.linalg.norm(X, axis=1)\n",
    "items_with_embeddings[\"_norm\"] = norms\n",
    "\n",
    "# pairwise KS vs first dataset (diagnostic)\n",
    "datasets = items_with_embeddings[\"source\"].astype(str).unique().tolist()\n",
    "datasets = datasets[:5]  # keep core output small\n",
    "\n",
    "rows = []\n",
    "if len(datasets) >= 2:\n",
    "    base = datasets[0]\n",
    "    a = items_with_embeddings[items_with_embeddings[\"source\"].astype(str) == base][\"_norm\"].tolist()\n",
    "    for ds in datasets[1:]:\n",
    "        b = items_with_embeddings[items_with_embeddings[\"source\"].astype(str) == ds][\"_norm\"].tolist()\n",
    "        tr = ks_2samp(a, b, name=f\"ks_norm__{base}__vs__{ds}\")\n",
    "        rows.append({\"base\":base,\"compare\":ds,\"statistic\":tr.statistic,\"p_value\":tr.p_value,\"n_a\":tr.n_a,\"n_b\":tr.n_b,\"notes\":tr.notes})\n",
    "\n",
    "tab = pd.DataFrame(rows)\n",
    "display(tab)\n",
    "\n",
    "(tab_path := qa_dir / \"drift_ks_norms_table.parquet\")\n",
    "tab.to_parquet(tab_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fa65ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core diagnostic 7B — Drift visualization: embedding norm ECDF by dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(7, 4))\n",
    "\n",
    "for ds in datasets:\n",
    "    x = items_with_embeddings[items_with_embeddings[\"source\"].astype(str) == ds][\"_norm\"].to_numpy()\n",
    "    x = x[np.isfinite(x)]\n",
    "    if x.size == 0:\n",
    "        continue\n",
    "    xs = np.sort(x)\n",
    "    ys = np.arange(1, xs.size + 1) / xs.size\n",
    "    plt.plot(xs, ys, label=str(ds))\n",
    "\n",
    "plt.title(\"Embedding norm ECDF by dataset (diagnostic)\")\n",
    "plt.xlabel(\"norm\")\n",
    "plt.ylabel(\"ECDF\")\n",
    "plt.legend(fontsize=7)\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = plots_dir / \"drift_norm_ecdf_by_dataset.png\"\n",
    "save_and_display(fig, out_path)\n",
    "\n",
    "register_plot(\n",
    "    viz_records,\n",
    "    stage=\"stage_02_embeddings\",\n",
    "    plot_id=\"drift_norm_ecdf_by_dataset\",\n",
    "    title=\"Embedding norm ECDF by dataset\",\n",
    "    path=out_path,\n",
    "    tags=[\"core\", \"embeddings\", \"drift\", \"dataset\"],\n",
    "    is_core=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bdd586",
   "metadata": {},
   "source": [
    "**Interpretation**: Large ECDF shifts indicate dataset drift.\n",
    "\n",
    "**Warning signs**: Datasets with clearly separated ECDF curves; consider normalizing or rebalancing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbc679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extended (deep) — YData Profiling report (HTML) (optional heavy)\n",
    "from histo_cartography.eda_reports import ydata_profiling_report\n",
    "\n",
    "if EDA_LEVEL == \"deep\":\n",
    "    out_html = eda_dir / \"ydata_profile_items_with_embeddings.html\"\n",
    "    p = ydata_profiling_report(items_with_embeddings.drop(columns=[\"vector\"], errors=\"ignore\"), out_html=out_html, sample_rows=2000, minimal=True)\n",
    "    if p:\n",
    "        print(\"✅ wrote profiling report:\", p)\n",
    "    else:\n",
    "        print(\"⚠️ ydata-profiling not available\")\n",
    "else:\n",
    "    print(\"EDA_LEVEL != deep (skipping profiling)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88da197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write viz index (parquet + csv) + show a small preview\n",
    "from IPython.display import display\n",
    "from histo_cartography.viz import write_viz_index, viz_records_to_df\n",
    "\n",
    "viz_index_path = stage_dir / \"viz_index.parquet\"\n",
    "write_viz_index(viz_records, out_parquet=viz_index_path, out_csv=stage_dir / \"viz_index.csv\")\n",
    "\n",
    "viz_df = viz_records_to_df(viz_records)\n",
    "display(viz_df.head(50))\n",
    "print(\"✅ wrote viz_index:\", viz_index_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75defd00",
   "metadata": {},
   "source": [
    "## Next actions\n",
    "\n",
    "- If **dataset separability** is very high:\n",
    "  - expect “dataset islands” in Stage 03 clustering.\n",
    "  - consider stain normalization, domain balancing, or enabling morphology/text fusion (carefully; avoid label leakage).\n",
    "- If embeddings look **collapsed** (very low variance / narrow norm histogram):\n",
    "  - verify image paths are valid\n",
    "  - check ResNet preprocessing and image decoding\n",
    "  - try re-running Stage 02 with a different embedding model.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
