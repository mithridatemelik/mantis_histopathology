{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7a70473",
   "metadata": {},
   "source": [
    "# Stage 04 — Agent 1 cluster cleanup (semantic enrichment, glass-box)\n",
    "\n",
    "This notebook reads **Stage 03** `items_with_clusters.parquet` and runs **Agent 1** to produce **semantic cluster labels**.\n",
    "\n",
    "Outputs (parquet-first):\n",
    "- `exports/stage_04_agent1_cleanup/clusters_semantic.parquet`\n",
    "- `exports/stage_04_agent1_cleanup/agent1_memory.parquet`\n",
    "- `exports/stage_04_agent1_cleanup/items_after_agent1.parquet`\n",
    "\n",
    "**Critical rule**: semantics must be *inspectable*:\n",
    "- representative montages for clusters\n",
    "- tables showing label/dataset mixture\n",
    "- uniqueness stabilization (no duplicate `cluster_name`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66861e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Colab-first setup ---\n",
    "import os, sys, time\n",
    "from pathlib import Path\n",
    "\n",
    "FORCE_REBUILD = False\n",
    "FAST_MODE = True\n",
    "EDA_LEVEL = \"core\"  # \"core\" | \"standard\" | \"deep\"\n",
    "\n",
    "SHOW_PLOTS = True\n",
    "SAVE_PLOTS = True\n",
    "\n",
    "DRIVE_SEARCH_BASE = \"/content/drive/MyDrive\"\n",
    "\n",
    "def _is_colab() -> bool:\n",
    "    return \"google.colab\" in sys.modules\n",
    "\n",
    "if _is_colab():\n",
    "    from google.colab import drive  # type: ignore\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "def _resolve_project_root() -> Path:\n",
    "    ev = os.environ.get(\"HISTO_PROJECT_ROOT\")\n",
    "    if ev and Path(ev).exists():\n",
    "        return Path(ev)\n",
    "\n",
    "    base = Path(DRIVE_SEARCH_BASE)\n",
    "    candidates = []\n",
    "    if base.exists():\n",
    "        for p in base.glob(\"**/pipeline_config.yaml\"):\n",
    "            parent = p.parent\n",
    "            if (parent / \"label_taxonomy.yaml\").exists():\n",
    "                candidates.append(parent)\n",
    "    if candidates:\n",
    "        candidates = sorted(candidates, key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "        return candidates[0]\n",
    "\n",
    "    p = Path.cwd()\n",
    "    for _ in range(10):\n",
    "        if (p / \"pipeline_config.yaml\").exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    raise FileNotFoundError(\"Could not resolve PROJECT_ROOT. Set HISTO_PROJECT_ROOT env var.\")\n",
    "\n",
    "PROJECT_ROOT = _resolve_project_root()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "\n",
    "# Install deps\n",
    "import subprocess\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", \"-r\", str(PROJECT_ROOT / \"requirements.txt\")])\n",
    "\n",
    "import yaml\n",
    "cfg = yaml.safe_load((PROJECT_ROOT / \"pipeline_config.yaml\").read_text())\n",
    "\n",
    "EXPORTS_DIR = PROJECT_ROOT / str(cfg.get(\"paths\", {}).get(\"exports_dir\", \"exports\"))\n",
    "EXPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SAFE_MODE = bool(cfg.get(\"project\", {}).get(\"safe_mode\", True))\n",
    "SEED = int(cfg.get(\"project\", {}).get(\"seed\", 1337))\n",
    "\n",
    "print(\"SAFE_MODE:\", SAFE_MODE, \"| EDA_LEVEL:\", EDA_LEVEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008a8fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Secrets (do NOT print tokens) ---\n",
    "import os\n",
    "\n",
    "# Agentic stages require OPENAI_API_KEY.\n",
    "# In Colab: Runtime → Secrets → add OPENAI_API_KEY\n",
    "assert os.environ.get(\"OPENAI_API_KEY\"), \"Missing OPENAI_API_KEY. Set it in Colab Secrets or env vars.\"\n",
    "print(\"✅ OPENAI_API_KEY is set (value not printed).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7f0018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Stage paths + registries ---\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from histo_cartography.viz import ensure_dir, save_and_display, register_plot, display_image\n",
    "from histo_cartography.artifact_registry import register_artifact, append_stage_manifest\n",
    "from histo_cartography.critic import run_critic, write_critic_report, critic_result_table, critic_issues_table\n",
    "\n",
    "stage_in_items = EXPORTS_DIR / \"stage_03_clustering\" / \"items_with_clusters.parquet\"\n",
    "stage_in_centroids = EXPORTS_DIR / \"stage_03_clustering\" / \"cluster_centroids.parquet\"\n",
    "assert stage_in_items.exists(), f\"missing upstream parquet: {stage_in_items}\"\n",
    "assert stage_in_centroids.exists(), f\"missing upstream parquet: {stage_in_centroids}\"\n",
    "\n",
    "stage_dir = EXPORTS_DIR / \"stage_04_agent1_cleanup\"\n",
    "plots_dir = ensure_dir(stage_dir / \"plots\")\n",
    "qa_dir = ensure_dir(stage_dir / \"qa\")\n",
    "eda_dir = ensure_dir(stage_dir / \"eda\")\n",
    "\n",
    "clusters_semantic_path = stage_dir / \"clusters_semantic.parquet\"\n",
    "agent1_memory_path = stage_dir / \"agent1_memory.parquet\"\n",
    "items_after_agent1_path = stage_dir / \"items_after_agent1.parquet\"\n",
    "\n",
    "viz_records = []\n",
    "\n",
    "print(\"stage_dir:\", stage_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ef3ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load upstream data (Stage 03) ---\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "items = pd.read_parquet(stage_in_items)\n",
    "centroids = pd.read_parquet(stage_in_centroids)\n",
    "\n",
    "display(items.head(3))\n",
    "print(\"items shape:\", items.shape)\n",
    "print(\"centroids shape:\", centroids.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e61801",
   "metadata": {},
   "source": [
    "## PEEP — Preflight health + EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1983651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEEP (1/4) — Overview table\n",
    "from IPython.display import display\n",
    "from histo_cartography.eda_reports import df_overview_table\n",
    "\n",
    "display(df_overview_table(items, max_cols=45).head(45))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2a7ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEEP (2/4) — Cluster size distribution (excluding -1)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vc = items[\"cluster_id\"].astype(int).value_counts()\n",
    "vc_no_noise = vc[vc.index != -1]\n",
    "\n",
    "fig = plt.figure(figsize=(7, 4))\n",
    "plt.hist(vc_no_noise.values, bins=min(30, max(5, len(vc_no_noise))), edgecolor=\"black\")\n",
    "plt.title(\"Stage 04 PEEP: cluster size distribution (excluding -1)\")\n",
    "plt.xlabel(\"cluster size\")\n",
    "plt.ylabel(\"count of clusters\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = plots_dir / \"peep_cluster_size_hist.png\"\n",
    "save_and_display(fig, out_path)\n",
    "register_plot(viz_records, stage=\"stage_04_agent1_cleanup\", plot_id=\"peep_cluster_size_hist\", title=\"PEEP cluster size distribution (excluding -1)\", path=out_path, tags=[\"peep\",\"clustering\"], is_core=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c44919",
   "metadata": {},
   "source": [
    "**Interpretation**: Agent 1 will name clusters; tiny clusters may be noisy and hard to name.\n",
    "\n",
    "**Warning signs**: many tiny clusters → consider revisiting Stage 03 parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cc082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEEP (3/4) — Montage of the largest cluster (glass-box sanity check)\n",
    "from histo_cartography.image_viz import montage_by_cluster\n",
    "\n",
    "largest_cluster_id = int(vc_no_noise.index[0]) if len(vc_no_noise) else 0\n",
    "out_path = plots_dir / (\"peep_montage_largest_cluster_\" + str(largest_cluster_id) + \".png\")\n",
    "montage_by_cluster(items, cluster_id=largest_cluster_id, out_path=out_path, image_col=\"image_path\", n=36, random_state=SEED)\n",
    "display_image(out_path)\n",
    "\n",
    "register_plot(viz_records, stage=\"stage_04_agent1_cleanup\", plot_id=\"peep_montage_largest_cluster_\" + str(largest_cluster_id), title=\"PEEP montage: largest cluster \" + str(largest_cluster_id), path=out_path, tags=[\"peep\",\"montage\",\"cluster\"], is_core=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10418bd",
   "metadata": {},
   "source": [
    "**Interpretation**: A quick visual check that clusters correspond to meaningful visual motifs.\n",
    "\n",
    "**Warning signs**: montage looks random/noisy/artifact-heavy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6be60f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEEP (4/4) — Critic gates (items_with_clusters)\n",
    "from IPython.display import display\n",
    "\n",
    "critic_in = run_critic(\n",
    "    df=items,\n",
    "    stage=\"stage_04_agent1_cleanup\",\n",
    "    gate=\"peep_items_with_clusters\",\n",
    "    required_cols=[\"item_id\",\"cluster_id\",\"image_path\",\"label\",\"source\",\"vector\"],\n",
    "    id_col=\"item_id\",\n",
    "    min_rows=100 if not SAFE_MODE else 10,\n",
    "    key_nonnull_cols=[\"item_id\",\"cluster_id\",\"image_path\"],\n",
    "    vector_col=\"vector\",\n",
    ")\n",
    "\n",
    "write_critic_report(critic_in, qa_dir / \"critic_peep_items_with_clusters.json\")\n",
    "display(critic_result_table(critic_in))\n",
    "display(critic_issues_table(critic_in).head(50))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461b8198",
   "metadata": {},
   "source": [
    "## Stage logic — Agent 1 semantic enrichment (idempotent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c2109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Build per-cluster evidence summaries + run Agent 1 ---\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from histo_cartography.exports import save_parquet\n",
    "from histo_cartography.agentic import run_agent1_cluster_cleanup\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Optional label taxonomy for human-readable names in prompts\n",
    "tax_path = PROJECT_ROOT / \"label_taxonomy.yaml\"\n",
    "label_map = {}\n",
    "if tax_path.exists():\n",
    "    tax = yaml.safe_load(tax_path.read_text())\n",
    "    for code, spec in (tax.get(\"labels\", {}) or {}).items():\n",
    "        label_map[str(code)] = str(spec.get(\"name\", code))\n",
    "\n",
    "def dominant_labels(df: pd.DataFrame, top_k: int = 5):\n",
    "    vc = df[\"label\"].astype(str).value_counts(dropna=False)\n",
    "    total = float(len(df)) if len(df) else 1.0\n",
    "    out = []\n",
    "    for label, c in vc.head(top_k).items():\n",
    "        out.append({\"label\": str(label), \"label_name\": label_map.get(str(label), str(label)), \"count\": int(c), \"frac\": float(c)/total})\n",
    "    return out\n",
    "\n",
    "# Build one-row-per-cluster evidence summaries used by Agent 1 (cheap, inspectable)\n",
    "summ_rows = []\n",
    "for cid, g in items.groupby(\"cluster_id\"):\n",
    "    cid = int(cid)\n",
    "    dom = dominant_labels(g, top_k=5)\n",
    "    sample_texts = [d[\"label_name\"] for d in dom]  # keep prompts short\n",
    "    summ_rows.append({\"cluster_id\": cid, \"n_items\": int(len(g)), \"dominant_labels\": dom, \"sample_texts\": sample_texts})\n",
    "\n",
    "clusters_summary = pd.DataFrame(summ_rows).sort_values(\"cluster_id\").reset_index(drop=True)\n",
    "\n",
    "if clusters_semantic_path.exists() and agent1_memory_path.exists() and items_after_agent1_path.exists() and not FORCE_REBUILD:\n",
    "    clusters_semantic = pd.read_parquet(clusters_semantic_path)\n",
    "    agent1_memory = pd.read_parquet(agent1_memory_path)\n",
    "    items_after_agent1 = pd.read_parquet(items_after_agent1_path)\n",
    "    print(\"✅ Loaded existing agent1 outputs:\", clusters_semantic.shape, agent1_memory.shape, items_after_agent1.shape)\n",
    "else:\n",
    "    clusters_semantic, agent1_memory = run_agent1_cluster_cleanup(\n",
    "        clusters_summary=clusters_summary,\n",
    "        out_clusters_path=clusters_semantic_path,\n",
    "        out_memory_path=agent1_memory_path,\n",
    "        model=str(cfg.get(\"agentic\", {}).get(\"agent1\", {}).get(\"model\", \"gpt-4o-mini\")),\n",
    "        temperature=float(cfg.get(\"agentic\", {}).get(\"agent1\", {}).get(\"temperature\", 0.2)),\n",
    "        max_clusters=int(cfg.get(\"agentic\", {}).get(\"agent1\", {}).get(\"max_clusters\", 999999)),\n",
    "        force_rebuild=FORCE_REBUILD,\n",
    "    )\n",
    "\n",
    "    # Join back to items\n",
    "    items_after_agent1 = items.merge(\n",
    "        clusters_semantic[[\"cluster_id\",\"cluster_name\",\"cluster_description\",\"cluster_keywords\"]],\n",
    "        on=\"cluster_id\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    save_parquet(items_after_agent1, items_after_agent1_path)\n",
    "\n",
    "runtime_sec = time.time() - t0\n",
    "print(\"runtime_sec:\", round(runtime_sec, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e36e572",
   "metadata": {},
   "source": [
    "## CHECKPOINT — After Agent 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95177410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKPOINT: critic on clusters_semantic (must have unique names)\n",
    "from IPython.display import display\n",
    "\n",
    "required = [\"cluster_id\",\"cluster_name\",\"cluster_description\",\"cluster_keywords\"]\n",
    "\n",
    "critic_clusters = run_critic(\n",
    "    df=clusters_semantic,\n",
    "    stage=\"stage_04_agent1_cleanup\",\n",
    "    gate=\"checkpoint_clusters_semantic\",\n",
    "    required_cols=required,\n",
    "    id_col=\"cluster_id\",\n",
    "    min_rows=2,\n",
    "    key_nonnull_cols=[\"cluster_id\",\"cluster_name\"],\n",
    ")\n",
    "\n",
    "# Hard uniqueness check (must pass)\n",
    "name_dups = clusters_semantic[\"cluster_name\"].astype(str).duplicated().sum()\n",
    "if name_dups > 0:\n",
    "    critic_clusters.fails.append(\"cluster_name_not_unique: duplicate_count=\" + str(int(name_dups)))\n",
    "    critic_clusters.passed = False\n",
    "\n",
    "write_critic_report(critic_clusters, qa_dir / \"critic_checkpoint_clusters_semantic.json\")\n",
    "display(critic_result_table(critic_clusters))\n",
    "display(critic_issues_table(critic_clusters).head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114da0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register artifacts + stage manifest\n",
    "schema_version = str(cfg.get(\"project\", {}).get(\"schema_version\", \"0.1.0\"))\n",
    "\n",
    "register_artifact(\n",
    "    project_root=PROJECT_ROOT,\n",
    "    stage=\"stage_04_agent1_cleanup\",\n",
    "    artifact=\"clusters_semantic\",\n",
    "    path=clusters_semantic_path,\n",
    "    schema_version=schema_version,\n",
    "    inputs=[stage_in_items],\n",
    "    df=clusters_semantic,\n",
    "    warnings_count=int(critic_clusters.warnings_count),\n",
    "    fails_count=int(critic_clusters.fails_count),\n",
    "    runtime_sec=float(runtime_sec),\n",
    "    notes=\"Agent 1 semantic cluster table\",\n",
    ")\n",
    "register_artifact(\n",
    "    project_root=PROJECT_ROOT,\n",
    "    stage=\"stage_04_agent1_cleanup\",\n",
    "    artifact=\"agent1_memory\",\n",
    "    path=agent1_memory_path,\n",
    "    schema_version=schema_version,\n",
    "    inputs=[stage_in_items],\n",
    "    df=agent1_memory,\n",
    "    warnings_count=int(critic_clusters.warnings_count),\n",
    "    fails_count=int(critic_clusters.fails_count),\n",
    "    runtime_sec=float(runtime_sec),\n",
    "    notes=\"Agent 1 memory (prompt/response history)\",\n",
    ")\n",
    "register_artifact(\n",
    "    project_root=PROJECT_ROOT,\n",
    "    stage=\"stage_04_agent1_cleanup\",\n",
    "    artifact=\"items_after_agent1\",\n",
    "    path=items_after_agent1_path,\n",
    "    schema_version=schema_version,\n",
    "    inputs=[stage_in_items, clusters_semantic_path],\n",
    "    df=items_after_agent1,\n",
    "    warnings_count=int(critic_clusters.warnings_count),\n",
    "    fails_count=int(critic_clusters.fails_count),\n",
    "    runtime_sec=float(runtime_sec),\n",
    "    notes=\"items + semantic cluster columns\",\n",
    ")\n",
    "\n",
    "append_stage_manifest(\n",
    "    project_root=PROJECT_ROOT,\n",
    "    stage=\"stage_04_agent1_cleanup\",\n",
    "    inputs=[stage_in_items, stage_in_centroids],\n",
    "    outputs=[clusters_semantic_path, agent1_memory_path, items_after_agent1_path],\n",
    "    schema_version=schema_version,\n",
    "    warnings_count=int(critic_clusters.warnings_count),\n",
    "    fails_count=int(critic_clusters.fails_count),\n",
    "    runtime_sec=float(runtime_sec),\n",
    "    notes=\"stage 04 run summary\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd85e75",
   "metadata": {},
   "source": [
    "## POST — Semantic health + glass-box checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST (1/4) — Cluster semantics table (length diagnostics)\n",
    "from IPython.display import display\n",
    "\n",
    "df = clusters_semantic.copy()\n",
    "df[\"name_len\"] = df[\"cluster_name\"].astype(str).map(len)\n",
    "df[\"desc_len\"] = df[\"cluster_description\"].astype(str).map(len)\n",
    "df[\"kw_len\"] = df[\"cluster_keywords\"].astype(str).map(lambda x: len(x) if isinstance(x, (list,tuple)) else len(str(x)))\n",
    "display(df[[\"cluster_id\",\"cluster_name\",\"name_len\",\"desc_len\",\"kw_len\"]].head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef2e42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST (2/4) — Name uniqueness / collision report (should be all unique)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vc = clusters_semantic[\"cluster_name\"].astype(str).value_counts()\n",
    "dups = vc[vc.values > 1]\n",
    "\n",
    "fig = plt.figure(figsize=(8, 3))\n",
    "if len(dups):\n",
    "    plt.bar(dups.index.astype(str), dups.values)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.title(\"⚠️ Duplicate cluster_name collisions (should be empty)\")\n",
    "else:\n",
    "    plt.bar([\"unique\"], [len(clusters_semantic)])\n",
    "    plt.title(\"✅ cluster_name uniqueness check passed\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = plots_dir / \"name_collision_report.png\"\n",
    "save_and_display(fig, out_path)\n",
    "register_plot(viz_records, stage=\"stage_04_agent1_cleanup\", plot_id=\"name_collision_report\", title=\"Name collision report\", path=out_path, tags=[\"post\",\"semantic\",\"uniqueness\"], is_core=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371faa44",
   "metadata": {},
   "source": [
    "**Interpretation**: Agent 1 must stabilize names so each cluster has a unique short label.\n",
    "\n",
    "**Warning signs**: any duplicates indicate stabilization failed; rerun Agent 1 with FORCE_REBUILD=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7cf92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST (3/4) — \"Junk semantics\" detector (heuristic flags)\n",
    "from IPython.display import display\n",
    "\n",
    "def is_junk(name: str) -> bool:\n",
    "    n = (name or \"\").strip().lower()\n",
    "    if len(n) < 3:\n",
    "        return True\n",
    "    junk_terms = [\"unknown\",\"other\",\"misc\",\"artifact\",\"noise\",\"junk\",\"background\"]\n",
    "    return any(t in n for t in junk_terms)\n",
    "\n",
    "flags = clusters_semantic.copy()\n",
    "flags[\"junk_name\"] = flags[\"cluster_name\"].astype(str).map(is_junk)\n",
    "flags[\"short_desc\"] = flags[\"cluster_description\"].astype(str).map(lambda s: len(s.strip()) < 20)\n",
    "\n",
    "flagged = flags[flags[\"junk_name\"] | flags[\"short_desc\"]].copy()\n",
    "display(flagged[[\"cluster_id\",\"cluster_name\",\"junk_name\",\"short_desc\"]].head(50))\n",
    "\n",
    "(flag_path := qa_dir / \"junk_semantics_flags.parquet\")\n",
    "flagged.to_parquet(flag_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58177680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST (4/4) — Critic summary (clusters_semantic)\n",
    "from IPython.display import display\n",
    "\n",
    "display(critic_result_table(critic_clusters))\n",
    "display(critic_issues_table(critic_clusters).head(50))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c4686b",
   "metadata": {},
   "source": [
    "## Core semantic visual verification (one montage per cell)\n",
    "Montages are the primary evidence backing semantic labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79213cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a few clusters for flashcard review (core)\n",
    "vc_sizes = items_after_agent1[\"cluster_id\"].astype(int).value_counts()\n",
    "vc_sizes = vc_sizes[vc_sizes.index != -1]\n",
    "review_cluster_ids = [int(x) for x in vc_sizes.head(2).index.tolist()]\n",
    "if len(flagged):\n",
    "    review_cluster_ids.append(int(flagged.iloc[0][\"cluster_id\"]))\n",
    "review_cluster_ids = list(dict.fromkeys(review_cluster_ids))[:3]\n",
    "print(\"review_cluster_ids:\", review_cluster_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeb65fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flashcard 1 — cluster semantics (if review_cluster_ids[0] exists)\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "if len(review_cluster_ids) > 0:\n",
    "    cid = review_cluster_ids[0]\n",
    "    row = clusters_semantic[clusters_semantic[\"cluster_id\"].astype(int) == int(cid)].iloc[0]\n",
    "    md = \"### Cluster \" + str(cid) + \": \" + str(row[\"cluster_name\"]) + \"\\n\\n\" +          \"**Description**: \" + str(row[\"cluster_description\"]) + \"\\n\\n\" +          \"**Keywords**: \" + str(row[\"cluster_keywords\"]) + \"\\n\"\n",
    "    display(Markdown(md))\n",
    "else:\n",
    "    print(\"not enough clusters for review\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e8962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montage 1 — Representative images for review_cluster_ids[0]\n",
    "from histo_cartography.image_viz import montage_by_cluster\n",
    "\n",
    "if len(review_cluster_ids) > 0:\n",
    "    cid = review_cluster_ids[0]\n",
    "    out_path = plots_dir / (\"montage_agent1_cluster_\" + str(cid) + \".png\")\n",
    "    montage_by_cluster(items_after_agent1, cluster_id=cid, out_path=out_path, image_col=\"image_path\", n=36, random_state=SEED)\n",
    "    display_image(out_path)\n",
    "    register_plot(viz_records, stage=\"stage_04_agent1_cleanup\", plot_id=\"montage_agent1_cluster_\" + str(cid), title=\"Agent1 cluster montage: \" + str(cid), path=out_path, tags=[\"core\",\"montage\",\"agent1\"], is_core=True)\n",
    "else:\n",
    "    print(\"not enough clusters for montage\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ca8818",
   "metadata": {},
   "source": [
    "**Interpretation**: Does the montage visually match the semantic label? If not, either clustering is off (Stage 03) or Agent 1 needs better evidence.\n",
    "\n",
    "**Warning signs**: montage contradicts label; re-run with better prompts/evidence or adjust clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f03b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flashcard 2 — cluster semantics (if review_cluster_ids[1] exists)\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "if len(review_cluster_ids) > 1:\n",
    "    cid = review_cluster_ids[1]\n",
    "    row = clusters_semantic[clusters_semantic[\"cluster_id\"].astype(int) == int(cid)].iloc[0]\n",
    "    md = \"### Cluster \" + str(cid) + \": \" + str(row[\"cluster_name\"]) + \"\\n\\n\" +          \"**Description**: \" + str(row[\"cluster_description\"]) + \"\\n\\n\" +          \"**Keywords**: \" + str(row[\"cluster_keywords\"]) + \"\\n\"\n",
    "    display(Markdown(md))\n",
    "else:\n",
    "    print(\"not enough clusters for review\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ead1232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montage 2 — Representative images for review_cluster_ids[1]\n",
    "from histo_cartography.image_viz import montage_by_cluster\n",
    "\n",
    "if len(review_cluster_ids) > 1:\n",
    "    cid = review_cluster_ids[1]\n",
    "    out_path = plots_dir / (\"montage_agent1_cluster_\" + str(cid) + \".png\")\n",
    "    montage_by_cluster(items_after_agent1, cluster_id=cid, out_path=out_path, image_col=\"image_path\", n=36, random_state=SEED)\n",
    "    display_image(out_path)\n",
    "    register_plot(viz_records, stage=\"stage_04_agent1_cleanup\", plot_id=\"montage_agent1_cluster_\" + str(cid), title=\"Agent1 cluster montage: \" + str(cid), path=out_path, tags=[\"core\",\"montage\",\"agent1\"], is_core=True)\n",
    "else:\n",
    "    print(\"not enough clusters for montage\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18409328",
   "metadata": {},
   "source": [
    "**Interpretation**: Does the montage visually match the semantic label? If not, either clustering is off (Stage 03) or Agent 1 needs better evidence.\n",
    "\n",
    "**Warning signs**: montage contradicts label; re-run with better prompts/evidence or adjust clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7c437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flashcard 3 — cluster semantics (if review_cluster_ids[2] exists)\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "if len(review_cluster_ids) > 2:\n",
    "    cid = review_cluster_ids[2]\n",
    "    row = clusters_semantic[clusters_semantic[\"cluster_id\"].astype(int) == int(cid)].iloc[0]\n",
    "    md = \"### Cluster \" + str(cid) + \": \" + str(row[\"cluster_name\"]) + \"\\n\\n\" +          \"**Description**: \" + str(row[\"cluster_description\"]) + \"\\n\\n\" +          \"**Keywords**: \" + str(row[\"cluster_keywords\"]) + \"\\n\"\n",
    "    display(Markdown(md))\n",
    "else:\n",
    "    print(\"not enough clusters for review\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cf2e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montage 3 — Representative images for review_cluster_ids[2]\n",
    "from histo_cartography.image_viz import montage_by_cluster\n",
    "\n",
    "if len(review_cluster_ids) > 2:\n",
    "    cid = review_cluster_ids[2]\n",
    "    out_path = plots_dir / (\"montage_agent1_cluster_\" + str(cid) + \".png\")\n",
    "    montage_by_cluster(items_after_agent1, cluster_id=cid, out_path=out_path, image_col=\"image_path\", n=36, random_state=SEED)\n",
    "    display_image(out_path)\n",
    "    register_plot(viz_records, stage=\"stage_04_agent1_cleanup\", plot_id=\"montage_agent1_cluster_\" + str(cid), title=\"Agent1 cluster montage: \" + str(cid), path=out_path, tags=[\"core\",\"montage\",\"agent1\"], is_core=True)\n",
    "else:\n",
    "    print(\"not enough clusters for montage\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcd9658",
   "metadata": {},
   "source": [
    "**Interpretation**: Does the montage visually match the semantic label? If not, either clustering is off (Stage 03) or Agent 1 needs better evidence.\n",
    "\n",
    "**Warning signs**: montage contradicts label; re-run with better prompts/evidence or adjust clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4a4915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core plot — Dataset mix per cluster (top clusters)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "top_clusters = vc_sizes.head(10).index.tolist()\n",
    "sub = items_after_agent1[items_after_agent1[\"cluster_id\"].astype(int).isin(top_clusters)].copy()\n",
    "\n",
    "ct = pd.crosstab(sub[\"cluster_id\"].astype(int), sub[\"source\"].astype(str))\n",
    "ctn = ct.div(ct.sum(axis=1), axis=0)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "bottom = None\n",
    "for col in ctn.columns:\n",
    "    vals = ctn[col].values\n",
    "    if bottom is None:\n",
    "        plt.bar(ctn.index.astype(str), vals, label=col)\n",
    "        bottom = vals\n",
    "    else:\n",
    "        plt.bar(ctn.index.astype(str), vals, bottom=bottom, label=col)\n",
    "        bottom = bottom + vals\n",
    "\n",
    "plt.title(\"Dataset mix per cluster (top 10 clusters)\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"fraction\")\n",
    "plt.legend(fontsize=7, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = plots_dir / \"dataset_mix_top_clusters.png\"\n",
    "save_and_display(fig, out_path)\n",
    "register_plot(viz_records, stage=\"stage_04_agent1_cleanup\", plot_id=\"dataset_mix_top_clusters\", title=\"Dataset mix per cluster (top clusters)\", path=out_path, tags=[\"core\",\"semantic\",\"dataset_mix\"], is_core=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfe05e4",
   "metadata": {},
   "source": [
    "**Interpretation**: Mixed clusters across datasets are often more robust; single-dataset clusters may reflect domain artifacts.\n",
    "\n",
    "**Warning signs**: many clusters dominated by one dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc8f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core plot — Label mix per cluster (top clusters)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ct = pd.crosstab(sub[\"cluster_id\"].astype(int), sub[\"label\"].astype(str))\n",
    "ctn = ct.div(ct.sum(axis=1), axis=0)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "bottom = None\n",
    "for col in ctn.columns[:10]:\n",
    "    vals = ctn[col].values\n",
    "    if bottom is None:\n",
    "        plt.bar(ctn.index.astype(str), vals, label=col)\n",
    "        bottom = vals\n",
    "    else:\n",
    "        plt.bar(ctn.index.astype(str), vals, bottom=bottom, label=col)\n",
    "        bottom = bottom + vals\n",
    "\n",
    "plt.title(\"Label mix per cluster (top 10 clusters)\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"fraction\")\n",
    "plt.legend(fontsize=7, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = plots_dir / \"label_mix_top_clusters.png\"\n",
    "save_and_display(fig, out_path)\n",
    "register_plot(viz_records, stage=\"stage_04_agent1_cleanup\", plot_id=\"label_mix_top_clusters\", title=\"Label mix per cluster (top clusters)\", path=out_path, tags=[\"core\",\"semantic\",\"label_mix\"], is_core=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2017ff62",
   "metadata": {},
   "source": [
    "**Interpretation**: Label mix is a diagnostic; mixed clusters can be valid, but large highly mixed clusters may be too broad.\n",
    "\n",
    "**Warning signs**: no dominant signal across labels in many clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5e53a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic-vs-visual consistency spot check (nearest clusters by centroid similarity)\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "\n",
    "if len(review_cluster_ids):\n",
    "    cid = int(review_cluster_ids[0])\n",
    "else:\n",
    "    cid = int(vc_sizes.index[0])\n",
    "\n",
    "C = centroids.sort_values(\"cluster_id\").copy()\n",
    "vecs = np.asarray(C[\"vector\"].tolist(), dtype=np.float32)\n",
    "vecs = vecs / (np.linalg.norm(vecs, axis=1, keepdims=True) + 1e-12)\n",
    "ids = C[\"cluster_id\"].astype(int).tolist()\n",
    "\n",
    "i = ids.index(cid) if cid in ids else 0\n",
    "sims = vecs @ vecs[i]\n",
    "order = np.argsort(-sims)[:10]\n",
    "nn = pd.DataFrame({\"cluster_id\":[ids[j] for j in order], \"similarity\":[float(sims[j]) for j in order]})\n",
    "nn = nn.merge(clusters_semantic[[\"cluster_id\",\"cluster_name\"]], on=\"cluster_id\", how=\"left\")\n",
    "display(nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5629d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write viz index (parquet + csv) + show preview\n",
    "from IPython.display import display\n",
    "from histo_cartography.viz import write_viz_index, viz_records_to_df\n",
    "\n",
    "viz_index_path = stage_dir / \"viz_index.parquet\"\n",
    "write_viz_index(viz_records, out_parquet=viz_index_path, out_csv=stage_dir / \"viz_index.csv\")\n",
    "\n",
    "viz_df = viz_records_to_df(viz_records)\n",
    "display(viz_df.head(150))\n",
    "print(\"✅ wrote viz_index:\", viz_index_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5863dd03",
   "metadata": {},
   "source": [
    "## Next actions\n",
    "- Proceed to Stage 05 for Agent 2 linking + relationship verification.\n",
    "- If semantic labels look wrong: improve evidence (more representative samples) or revisit Stage 03 clustering."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
