{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f97e9fd8",
   "metadata": {},
   "source": [
    "# Stage 00 — Download & stage raw data (inventory only)\n",
    "\n",
    "This notebook prepares a **raw inventory index** (parquet-first) for downstream stages.\n",
    "\n",
    "Outputs:\n",
    "- `exports/stage_00_download/raw_index.parquet`\n",
    "\n",
    "Notes:\n",
    "- Stage 00 is **inventory-only**: it does *not* create stable `item_id`s or text prompts.\n",
    "- Stage 01 builds the canonical `items.parquet` used by the rest of the pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b7992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Colab-first setup ---\n",
    "import os, sys, time\n",
    "from pathlib import Path\n",
    "\n",
    "FORCE_REBUILD = False\n",
    "FAST_MODE = True\n",
    "EDA_LEVEL = \"core\"\n",
    "\n",
    "SHOW_PLOTS = True\n",
    "SAVE_PLOTS = True\n",
    "\n",
    "DRIVE_SEARCH_BASE = \"/content/drive/MyDrive\"\n",
    "\n",
    "def _is_colab() -> bool:\n",
    "    return \"google.colab\" in sys.modules\n",
    "\n",
    "if _is_colab():\n",
    "    from google.colab import drive  # type: ignore\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "def _resolve_project_root() -> Path:\n",
    "    ev = os.environ.get(\"HISTO_PROJECT_ROOT\")\n",
    "    if ev and Path(ev).exists():\n",
    "        return Path(ev)\n",
    "\n",
    "    base = Path(DRIVE_SEARCH_BASE)\n",
    "    candidates = []\n",
    "    if base.exists():\n",
    "        for p in base.glob(\"**/pipeline_config.yaml\"):\n",
    "            parent = p.parent\n",
    "            if (parent / \"label_taxonomy.yaml\").exists():\n",
    "                candidates.append(parent)\n",
    "    if candidates:\n",
    "        candidates = sorted(candidates, key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "        return candidates[0]\n",
    "\n",
    "    p = Path.cwd()\n",
    "    for _ in range(10):\n",
    "        if (p / \"pipeline_config.yaml\").exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    raise FileNotFoundError(\"Could not resolve PROJECT_ROOT. Set HISTO_PROJECT_ROOT env var.\")\n",
    "\n",
    "PROJECT_ROOT = _resolve_project_root()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "\n",
    "# Install deps\n",
    "import subprocess\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", \"-r\", str(PROJECT_ROOT / \"requirements.txt\")])\n",
    "\n",
    "import yaml\n",
    "cfg = yaml.safe_load((PROJECT_ROOT / \"pipeline_config.yaml\").read_text())\n",
    "\n",
    "EXPORTS_DIR = PROJECT_ROOT / str(cfg.get(\"paths\", {}).get(\"exports_dir\", \"exports\"))\n",
    "RAW_DIR = PROJECT_ROOT / str(cfg.get(\"paths\", {}).get(\"raw_dir\", \"data/raw\"))\n",
    "STAGING_DIR = PROJECT_ROOT / str(cfg.get(\"paths\", {}).get(\"staging_dir\", \"data/staging\"))\n",
    "EXPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "STAGING_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SAFE_MODE = bool(cfg.get(\"project\", {}).get(\"safe_mode\", True))\n",
    "SEED = int(cfg.get(\"project\", {}).get(\"seed\", 1337))\n",
    "\n",
    "print(\"SAFE_MODE:\", SAFE_MODE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6163fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Stage paths + registries ---\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from histo_cartography.viz import ensure_dir, save_and_display, register_plot\n",
    "from histo_cartography.artifact_registry import register_artifact, append_stage_manifest\n",
    "from histo_cartography.critic import run_critic, write_critic_report, critic_result_table, critic_issues_table\n",
    "\n",
    "stage_dir = EXPORTS_DIR / \"stage_00_download\"\n",
    "plots_dir = ensure_dir(stage_dir / \"plots\")\n",
    "qa_dir = ensure_dir(stage_dir / \"qa\")\n",
    "\n",
    "raw_index_path = stage_dir / \"raw_index.parquet\"\n",
    "viz_records = []\n",
    "\n",
    "print(\"stage_dir:\", stage_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf96de5",
   "metadata": {},
   "source": [
    "## PEEP — Config sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e6b739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEEP — show data config\n",
    "data_cfg = cfg.get(\"data\", {})\n",
    "dataset_keys = data_cfg.get(\"dataset_keys\") or [data_cfg.get(\"dataset_key\", \"CRC_VAL_HE_7K\")]\n",
    "split = str(data_cfg.get(\"split\", \"val\"))\n",
    "max_items = data_cfg.get(\"max_items_safe\", 512) if SAFE_MODE else data_cfg.get(\"max_items_full\", None)\n",
    "\n",
    "print(\"dataset_keys:\", dataset_keys)\n",
    "print(\"split:\", split)\n",
    "print(\"max_items:\", max_items)\n",
    "print(\"RAW_DIR:\", RAW_DIR)\n",
    "print(\"STAGING_DIR:\", STAGING_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f897daf0",
   "metadata": {},
   "source": [
    "## Stage logic — Download / stage + build raw_index (idempotent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be67e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Build raw_index.parquet ---\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from histo_cartography import datasets\n",
    "from histo_cartography.exports import save_parquet\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "data_cfg = cfg.get(\"data\", {})\n",
    "dataset_keys = data_cfg.get(\"dataset_keys\") or [data_cfg.get(\"dataset_key\", \"CRC_VAL_HE_7K\")]\n",
    "split = str(data_cfg.get(\"split\", \"val\"))\n",
    "\n",
    "verify_md5 = bool(data_cfg.get(\"download\", {}).get(\"verify_md5\", True))\n",
    "allow_large = bool(data_cfg.get(\"download\", {}).get(\"allow_large\", False))\n",
    "max_items = data_cfg.get(\"max_items_safe\", 512) if SAFE_MODE else data_cfg.get(\"max_items_full\", None)\n",
    "overwrite = bool(data_cfg.get(\"force_reextract\", False))\n",
    "\n",
    "def _provider_from_key(k: str) -> str:\n",
    "    if str(k).startswith(\"HF_\"):\n",
    "        return \"hf\"\n",
    "    if str(k).startswith(\"MEDMNIST_\"):\n",
    "        return \"medmnist\"\n",
    "    return \"zenodo_or_local\"\n",
    "\n",
    "if raw_index_path.exists() and not FORCE_REBUILD:\n",
    "    raw_index = pd.read_parquet(raw_index_path)\n",
    "    print(f\"✅ Loaded existing raw_index.parquet: {raw_index.shape}\")\n",
    "else:\n",
    "    parts = []\n",
    "    for dk in dataset_keys:\n",
    "        items_df, images_dir = datasets.prepare_dataset_to_staging(\n",
    "            dk,\n",
    "            raw_dir=RAW_DIR,\n",
    "            staging_dir=STAGING_DIR,\n",
    "            split=split,\n",
    "            safe_mode=SAFE_MODE,\n",
    "            max_items=max_items,\n",
    "            seed=SEED,\n",
    "            overwrite=overwrite,\n",
    "            verify_md5=verify_md5,\n",
    "            allow_large=allow_large,\n",
    "            mpp=float(data_cfg.get(\"mpp\", 0.5)),\n",
    "            use_text_modality=False,\n",
    "            text_template_version=\"v2_no_label\",\n",
    "        )\n",
    "        df = items_df.copy()\n",
    "        df[\"dataset_key\"] = str(dk)\n",
    "        df[\"provider\"] = _provider_from_key(str(dk))\n",
    "        df = df.rename(columns={\"source\": \"source_dataset\"})\n",
    "        keep = [\"dataset_key\", \"provider\", \"source_dataset\", \"split\", \"label\", \"image_path\", \"width\", \"height\", \"mpp\"]\n",
    "        df = df[keep]\n",
    "        parts.append(df)\n",
    "\n",
    "    raw_index = pd.concat(parts, ignore_index=True) if parts else pd.DataFrame()\n",
    "    assert len(raw_index) > 0, \"raw_index is empty. Check dataset_key and download settings.\"\n",
    "    assert raw_index[\"image_path\"].isna().sum() == 0, \"raw_index has missing image_path values.\"\n",
    "\n",
    "    save_parquet(raw_index, raw_index_path)\n",
    "\n",
    "runtime_sec = time.time() - t0\n",
    "print(\"runtime_sec:\", round(runtime_sec, 2))\n",
    "raw_index.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5050e5d",
   "metadata": {},
   "source": [
    "## CHECKPOINT — Raw index health gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cf4233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKPOINT: critic on raw_index\n",
    "from IPython.display import display\n",
    "\n",
    "crit_raw = run_critic(\n",
    "    df=raw_index,\n",
    "    stage=\"stage_00_download\",\n",
    "    gate=\"checkpoint_raw_index\",\n",
    "    required_cols=[\"dataset_key\",\"provider\",\"source_dataset\",\"split\",\"label\",\"image_path\",\"width\",\"height\",\"mpp\"],\n",
    "    id_col=None,\n",
    "    min_rows=10 if SAFE_MODE else 100,\n",
    "    key_nonnull_cols=[\"dataset_key\",\"image_path\"],\n",
    ")\n",
    "\n",
    "write_critic_report(crit_raw, qa_dir / \"critic_checkpoint_raw_index.json\")\n",
    "display(critic_result_table(crit_raw))\n",
    "display(critic_issues_table(crit_raw).head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6234fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register artifact + stage manifest\n",
    "schema_version = str(cfg.get(\"project\", {}).get(\"schema_version\", \"0.1.0\"))\n",
    "\n",
    "register_artifact(\n",
    "    project_root=PROJECT_ROOT,\n",
    "    stage=\"stage_00_download\",\n",
    "    artifact=\"raw_index\",\n",
    "    path=raw_index_path,\n",
    "    schema_version=schema_version,\n",
    "    inputs=[],\n",
    "    df=raw_index,\n",
    "    warnings_count=int(crit_raw.warnings_count),\n",
    "    fails_count=int(crit_raw.fails_count),\n",
    "    runtime_sec=float(runtime_sec),\n",
    "    notes=\"raw inventory parquet index\",\n",
    ")\n",
    "\n",
    "append_stage_manifest(\n",
    "    project_root=PROJECT_ROOT,\n",
    "    stage=\"stage_00_download\",\n",
    "    inputs=[],\n",
    "    outputs=[raw_index_path],\n",
    "    schema_version=schema_version,\n",
    "    warnings_count=int(crit_raw.warnings_count),\n",
    "    fails_count=int(crit_raw.fails_count),\n",
    "    runtime_sec=float(runtime_sec),\n",
    "    notes=\"stage 00 run summary\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a774d343",
   "metadata": {},
   "source": [
    "## POST — Inventory EDA (one plot per cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244d0fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST plot 1 — Dataset key distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vc = raw_index[\"dataset_key\"].astype(str).value_counts()\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "plt.bar(vc.index.astype(str), vc.values)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Dataset key distribution\")\n",
    "plt.ylabel(\"n items\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = plots_dir / \"dataset_key_distribution.png\"\n",
    "save_and_display(fig, out_path)\n",
    "register_plot(viz_records, stage=\"stage_00_download\", plot_id=\"dataset_key_distribution\", title=\"Dataset key distribution\", path=out_path, tags=[\"post\",\"distribution\"], is_core=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae5b8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST plot 2 — Label distribution (top 30)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vc = raw_index[\"label\"].astype(str).value_counts().head(30)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "plt.bar(vc.index.astype(str), vc.values)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Label distribution (top 30)\")\n",
    "plt.ylabel(\"n items\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = plots_dir / \"label_distribution_top30.png\"\n",
    "save_and_display(fig, out_path)\n",
    "register_plot(viz_records, stage=\"stage_00_download\", plot_id=\"label_distribution_top30\", title=\"Label distribution (top 30)\", path=out_path, tags=[\"post\",\"distribution\",\"label\"], is_core=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa81a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST plot 3 — Image resolution scatter (w × h)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.scatter(raw_index[\"width\"].astype(float), raw_index[\"height\"].astype(float), s=10, alpha=0.5)\n",
    "plt.xlabel(\"width\")\n",
    "plt.ylabel(\"height\")\n",
    "plt.title(\"Image resolution scatter\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = plots_dir / \"image_resolution_scatter.png\"\n",
    "save_and_display(fig, out_path)\n",
    "register_plot(viz_records, stage=\"stage_00_download\", plot_id=\"image_resolution_scatter\", title=\"Image resolution scatter\", path=out_path, tags=[\"post\",\"images\"], is_core=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0969d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write viz index (parquet + csv)\n",
    "from IPython.display import display\n",
    "from histo_cartography.viz import write_viz_index, viz_records_to_df\n",
    "\n",
    "viz_index_path = stage_dir / \"viz_index.parquet\"\n",
    "write_viz_index(viz_records, out_parquet=viz_index_path, out_csv=stage_dir / \"viz_index.csv\")\n",
    "display(viz_records_to_df(viz_records).head(50))\n",
    "print(\"✅ wrote viz_index:\", viz_index_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2210af87",
   "metadata": {},
   "source": [
    "## Next actions\n",
    "- Run Stage 01 to build canonical `items.parquet` with stable `item_id`s and text prompts (optional).\n",
    "- If downloads fail: check dataset keys, Drive permissions, and storage limits."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
