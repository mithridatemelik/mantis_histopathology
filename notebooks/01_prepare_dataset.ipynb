{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94e36732",
   "metadata": {},
   "source": [
    "# Stage 01 — Prepare canonical items table (parquet-first)\n",
    "\n",
    "This notebook creates the canonical `items.parquet` used by all downstream stages.\n",
    "\n",
    "Outputs:\n",
    "- `exports/stage_01_prepare/items.parquet`\n",
    "\n",
    "Key fields:\n",
    "- `item_id` (stable, deterministic)\n",
    "- `source`, `split`, `label`\n",
    "- `text` (optional; default template avoids label leakage)\n",
    "- `image_path`, `width`, `height`, `mpp`\n",
    "\n",
    "**Quality focus**\n",
    "- no missing `image_path`\n",
    "- unique `item_id`\n",
    "- label/dataset distributions visible before embedding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef14359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Colab-first setup ---\n",
    "import os, sys, time\n",
    "from pathlib import Path\n",
    "\n",
    "FORCE_REBUILD = False\n",
    "FAST_MODE = True\n",
    "EDA_LEVEL = \"core\"\n",
    "\n",
    "SHOW_PLOTS = True\n",
    "SAVE_PLOTS = True\n",
    "\n",
    "DRIVE_SEARCH_BASE = \"/content/drive/MyDrive\"\n",
    "\n",
    "def _is_colab() -> bool:\n",
    "    return \"google.colab\" in sys.modules\n",
    "\n",
    "if _is_colab():\n",
    "    from google.colab import drive  # type: ignore\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "def _resolve_project_root() -> Path:\n",
    "    ev = os.environ.get(\"HISTO_PROJECT_ROOT\")\n",
    "    if ev and Path(ev).exists():\n",
    "        return Path(ev)\n",
    "\n",
    "    base = Path(DRIVE_SEARCH_BASE)\n",
    "    candidates = []\n",
    "    if base.exists():\n",
    "        for p in base.glob(\"**/pipeline_config.yaml\"):\n",
    "            parent = p.parent\n",
    "            if (parent / \"label_taxonomy.yaml\").exists():\n",
    "                candidates.append(parent)\n",
    "    if candidates:\n",
    "        candidates = sorted(candidates, key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "        return candidates[0]\n",
    "\n",
    "    p = Path.cwd()\n",
    "    for _ in range(10):\n",
    "        if (p / \"pipeline_config.yaml\").exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    raise FileNotFoundError(\"Could not resolve PROJECT_ROOT. Set HISTO_PROJECT_ROOT env var.\")\n",
    "\n",
    "PROJECT_ROOT = _resolve_project_root()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "\n",
    "# Install deps\n",
    "import subprocess\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", \"-r\", str(PROJECT_ROOT / \"requirements.txt\")])\n",
    "\n",
    "import yaml\n",
    "cfg = yaml.safe_load((PROJECT_ROOT / \"pipeline_config.yaml\").read_text())\n",
    "\n",
    "EXPORTS_DIR = PROJECT_ROOT / str(cfg.get(\"paths\", {}).get(\"exports_dir\", \"exports\"))\n",
    "RAW_DIR = PROJECT_ROOT / str(cfg.get(\"paths\", {}).get(\"raw_dir\", \"data/raw\"))\n",
    "STAGING_DIR = PROJECT_ROOT / str(cfg.get(\"paths\", {}).get(\"staging_dir\", \"data/staging\"))\n",
    "\n",
    "EXPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "STAGING_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SAFE_MODE = bool(cfg.get(\"project\", {}).get(\"safe_mode\", True))\n",
    "SEED = int(cfg.get(\"project\", {}).get(\"seed\", 1337))\n",
    "\n",
    "print(\"SAFE_MODE:\", SAFE_MODE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5917ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Stage paths + registries ---\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from histo_cartography.viz import ensure_dir, save_and_display, register_plot, display_image\n",
    "from histo_cartography.artifact_registry import register_artifact, append_stage_manifest\n",
    "from histo_cartography.critic import run_critic, write_critic_report, critic_result_table, critic_issues_table\n",
    "\n",
    "stage_dir = EXPORTS_DIR / \"stage_01_prepare\"\n",
    "plots_dir = ensure_dir(stage_dir / \"plots\")\n",
    "qa_dir = ensure_dir(stage_dir / \"qa\")\n",
    "eda_dir = ensure_dir(stage_dir / \"eda\")\n",
    "\n",
    "items_path = stage_dir / \"items.parquet\"\n",
    "viz_records = []\n",
    "\n",
    "print(\"stage_dir:\", stage_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774d1199",
   "metadata": {},
   "source": [
    "## PEEP — Config sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2f52fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEEP — show data config\n",
    "data_cfg = cfg.get(\"data\", {})\n",
    "dataset_keys = data_cfg.get(\"dataset_keys\") or [data_cfg.get(\"dataset_key\", \"CRC_VAL_HE_7K\")]\n",
    "split = str(data_cfg.get(\"split\", \"val\"))\n",
    "max_items = data_cfg.get(\"max_items_safe\", 512) if SAFE_MODE else data_cfg.get(\"max_items_full\", None)\n",
    "\n",
    "use_text_modality = bool(data_cfg.get(\"use_text_modality\", False))\n",
    "text_template_version = str(data_cfg.get(\"text_template_version\", \"v2_no_label\"))\n",
    "\n",
    "print(\"dataset_keys:\", dataset_keys)\n",
    "print(\"split:\", split)\n",
    "print(\"max_items:\", max_items)\n",
    "print(\"use_text_modality:\", use_text_modality)\n",
    "print(\"text_template_version:\", text_template_version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a5ff61",
   "metadata": {},
   "source": [
    "## Stage logic — Build items.parquet (idempotent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475afeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Build items.parquet ---\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from histo_cartography import datasets\n",
    "from histo_cartography.exports import save_parquet\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "data_cfg = cfg.get(\"data\", {})\n",
    "dataset_keys = data_cfg.get(\"dataset_keys\") or [data_cfg.get(\"dataset_key\", \"CRC_VAL_HE_7K\")]\n",
    "split = str(data_cfg.get(\"split\", \"val\"))\n",
    "\n",
    "verify_md5 = bool(data_cfg.get(\"download\", {}).get(\"verify_md5\", True))\n",
    "allow_large = bool(data_cfg.get(\"download\", {}).get(\"allow_large\", False))\n",
    "max_items = data_cfg.get(\"max_items_safe\", 512) if SAFE_MODE else data_cfg.get(\"max_items_full\", None)\n",
    "overwrite = bool(data_cfg.get(\"force_reextract\", False))\n",
    "\n",
    "# Text config (avoid label leakage by default)\n",
    "use_text_modality = bool(data_cfg.get(\"use_text_modality\", False))\n",
    "text_template_version = str(data_cfg.get(\"text_template_version\", \"v2_no_label\"))\n",
    "\n",
    "if items_path.exists() and not FORCE_REBUILD:\n",
    "    items = pd.read_parquet(items_path)\n",
    "    print(f\"✅ Loaded existing items.parquet: {items.shape}\")\n",
    "else:\n",
    "    parts = []\n",
    "    for dk in dataset_keys:\n",
    "        items_df, images_dir = datasets.prepare_dataset_to_staging(\n",
    "            dk,\n",
    "            raw_dir=RAW_DIR,\n",
    "            staging_dir=STAGING_DIR,\n",
    "            split=split,\n",
    "            safe_mode=SAFE_MODE,\n",
    "            max_items=max_items,\n",
    "            seed=SEED,\n",
    "            overwrite=overwrite,\n",
    "            verify_md5=verify_md5,\n",
    "            allow_large=allow_large,\n",
    "            mpp=float(data_cfg.get(\"mpp\", 0.5)),\n",
    "            use_text_modality=use_text_modality,\n",
    "            text_template_version=text_template_version,\n",
    "        )\n",
    "        parts.append(items_df)\n",
    "\n",
    "    items = pd.concat(parts, ignore_index=True) if parts else pd.DataFrame()\n",
    "    assert len(items) > 0, \"items is empty. Check dataset_key and download settings.\"\n",
    "    assert items[\"image_path\"].isna().sum() == 0, \"items has missing image_path values.\"\n",
    "    assert items[\"item_id\"].isna().sum() == 0, \"items has missing item_id values.\"\n",
    "\n",
    "    # Uniqueness\n",
    "    dup = items[\"item_id\"].duplicated().sum()\n",
    "    if dup:\n",
    "        raise ValueError(f\"item_id not unique: duplicates={dup}\")\n",
    "\n",
    "    save_parquet(items, items_path)\n",
    "\n",
    "runtime_sec = time.time() - t0\n",
    "print(\"runtime_sec:\", round(runtime_sec, 2))\n",
    "items.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031016a6",
   "metadata": {},
   "source": [
    "## CHECKPOINT — Items health gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca6dd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKPOINT: critic on items\n",
    "from IPython.display import display\n",
    "\n",
    "crit_items = run_critic(\n",
    "    df=items,\n",
    "    stage=\"stage_01_prepare\",\n",
    "    gate=\"checkpoint_items\",\n",
    "    required_cols=[\"item_id\",\"source\",\"split\",\"label\",\"text\",\"image_path\",\"width\",\"height\",\"mpp\"],\n",
    "    id_col=\"item_id\",\n",
    "    min_rows=100 if not SAFE_MODE else 10,\n",
    "    key_nonnull_cols=[\"item_id\",\"image_path\"],\n",
    ")\n",
    "\n",
    "write_critic_report(crit_items, qa_dir / \"critic_checkpoint_items.json\")\n",
    "display(critic_result_table(crit_items))\n",
    "display(critic_issues_table(crit_items).head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c4a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register artifact + stage manifest\n",
    "schema_version = str(cfg.get(\"project\", {}).get(\"schema_version\", \"0.1.0\"))\n",
    "\n",
    "register_artifact(\n",
    "    project_root=PROJECT_ROOT,\n",
    "    stage=\"stage_01_prepare\",\n",
    "    artifact=\"items\",\n",
    "    path=items_path,\n",
    "    schema_version=schema_version,\n",
    "    inputs=[],\n",
    "    df=items,\n",
    "    warnings_count=int(crit_items.warnings_count),\n",
    "    fails_count=int(crit_items.fails_count),\n",
    "    runtime_sec=float(runtime_sec),\n",
    "    notes=\"canonical items table\",\n",
    ")\n",
    "\n",
    "append_stage_manifest(\n",
    "    project_root=PROJECT_ROOT,\n",
    "    stage=\"stage_01_prepare\",\n",
    "    inputs=[],\n",
    "    outputs=[items_path],\n",
    "    schema_version=schema_version,\n",
    "    warnings_count=int(crit_items.warnings_count),\n",
    "    fails_count=int(crit_items.fails_count),\n",
    "    runtime_sec=float(runtime_sec),\n",
    "    notes=\"stage 01 run summary\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627d8b46",
   "metadata": {},
   "source": [
    "## POST — EDA (one plot per cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5af7e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST plot 1 — Missingness\n",
    "from histo_cartography.eda_reports import plot_missingness\n",
    "\n",
    "fig = plot_missingness(items, top_k=25, title=\"Stage 01: items missingness (top 25)\")\n",
    "out_path = plots_dir / \"missingness_top25.png\"\n",
    "save_and_display(fig, out_path)\n",
    "register_plot(viz_records, stage=\"stage_01_prepare\", plot_id=\"missingness_top25\", title=\"Items missingness (top 25)\", path=out_path, tags=[\"post\",\"missingness\"], is_core=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb0a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST plot 2 — Source/dataset distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vc = items[\"source\"].astype(str).value_counts()\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "plt.bar(vc.index.astype(str), vc.values)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Source/dataset distribution\")\n",
    "plt.ylabel(\"n items\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = plots_dir / \"source_distribution.png\"\n",
    "save_and_display(fig, out_path)\n",
    "register_plot(viz_records, stage=\"stage_01_prepare\", plot_id=\"source_distribution\", title=\"Source/dataset distribution\", path=out_path, tags=[\"post\",\"distribution\",\"dataset\"], is_core=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02067063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST plot 3 — Label distribution (top 30)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vc = items[\"label\"].astype(str).value_counts().head(30)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "plt.bar(vc.index.astype(str), vc.values)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Label distribution (top 30)\")\n",
    "plt.ylabel(\"n items\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = plots_dir / \"label_distribution_top30.png\"\n",
    "save_and_display(fig, out_path)\n",
    "register_plot(viz_records, stage=\"stage_01_prepare\", plot_id=\"label_distribution_top30\", title=\"Label distribution (top 30)\", path=out_path, tags=[\"post\",\"distribution\",\"label\"], is_core=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d392c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST plot 4 — Image resolution scatter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.scatter(items[\"width\"].astype(float), items[\"height\"].astype(float), s=10, alpha=0.5)\n",
    "plt.xlabel(\"width\")\n",
    "plt.ylabel(\"height\")\n",
    "plt.title(\"Image resolution scatter\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = plots_dir / \"image_resolution_scatter.png\"\n",
    "save_and_display(fig, out_path)\n",
    "register_plot(viz_records, stage=\"stage_01_prepare\", plot_id=\"image_resolution_scatter\", title=\"Image resolution scatter\", path=out_path, tags=[\"post\",\"images\"], is_core=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b663968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST plot 5 — Text length histogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lens = items[\"text\"].astype(str).map(len)\n",
    "\n",
    "fig = plt.figure(figsize=(7, 4))\n",
    "plt.hist(lens, bins=30, edgecolor=\"black\")\n",
    "plt.title(\"Text length histogram\")\n",
    "plt.xlabel(\"chars\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = plots_dir / \"text_length_hist.png\"\n",
    "save_and_display(fig, out_path)\n",
    "register_plot(viz_records, stage=\"stage_01_prepare\", plot_id=\"text_length_hist\", title=\"Text length histogram\", path=out_path, tags=[\"post\",\"text\"], is_core=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b9f17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST plot 6 — Quick montage sample across labels (glass-box)\n",
    "from histo_cartography.image_viz import montage_sample\n",
    "\n",
    "out_path = plots_dir / \"montage_sample_stage01.png\"\n",
    "montage_sample(items, out_path=out_path, image_col=\"image_path\", n=49, random_state=SEED)\n",
    "display_image(out_path)\n",
    "register_plot(viz_records, stage=\"stage_01_prepare\", plot_id=\"montage_sample_stage01\", title=\"Sample montage (Stage 01)\", path=out_path, tags=[\"post\",\"montage\"], is_core=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0b916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write viz index (parquet + csv)\n",
    "from IPython.display import display\n",
    "from histo_cartography.viz import write_viz_index, viz_records_to_df\n",
    "\n",
    "viz_index_path = stage_dir / \"viz_index.parquet\"\n",
    "write_viz_index(viz_records, out_parquet=viz_index_path, out_csv=stage_dir / \"viz_index.csv\")\n",
    "display(viz_records_to_df(viz_records).head(60))\n",
    "print(\"✅ wrote viz_index:\", viz_index_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cda614c",
   "metadata": {},
   "source": [
    "## Next actions\n",
    "- Run Stage 02 to compute embeddings.\n",
    "- If you enabled `use_text_modality=True`, ensure `text_template_version` does not leak labels unless intended."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
