{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7934294",
   "metadata": {},
   "source": [
    "# Stage 03 — Cluster embeddings / cartography (parquet-first, visual-first)\n",
    "\n",
    "This notebook reads **Stage 02** `items_with_embeddings.parquet`, performs clustering (UMAP → HDBSCAN sweep with safe fallback), and writes:\n",
    "\n",
    "- `exports/stage_03_clustering/items_with_clusters.parquet` (adds `cluster_id` and 2D coords `x`,`y`)\n",
    "- `exports/stage_03_clustering/cluster_centroids.parquet`\n",
    "\n",
    "**Quality focus**\n",
    "- Cluster quality is extremely sensitive to embedding health (Stage 02).\n",
    "- This stage adds **core cartography plots** + cluster purity/mix checks before agentic enrichment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d72112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Colab-first setup (safe defaults) ---\n",
    "import os, sys, time\n",
    "from pathlib import Path\n",
    "\n",
    "FORCE_REBUILD = False\n",
    "FAST_MODE = True\n",
    "EDA_LEVEL = \"core\"  # \"core\" | \"standard\" | \"deep\"\n",
    "\n",
    "SHOW_PLOTS = True\n",
    "SAVE_PLOTS = True\n",
    "\n",
    "DRIVE_SEARCH_BASE = \"/content/drive/MyDrive\"\n",
    "\n",
    "def _is_colab() -> bool:\n",
    "    return \"google.colab\" in sys.modules\n",
    "\n",
    "if _is_colab():\n",
    "    from google.colab import drive  # type: ignore\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "def _resolve_project_root() -> Path:\n",
    "    ev = os.environ.get(\"HISTO_PROJECT_ROOT\")\n",
    "    if ev and Path(ev).exists():\n",
    "        return Path(ev)\n",
    "\n",
    "    base = Path(DRIVE_SEARCH_BASE)\n",
    "    candidates = []\n",
    "    if base.exists():\n",
    "        for p in base.glob(\"**/pipeline_config.yaml\"):\n",
    "            parent = p.parent\n",
    "            if (parent / \"label_taxonomy.yaml\").exists():\n",
    "                candidates.append(parent)\n",
    "    if candidates:\n",
    "        candidates = sorted(candidates, key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "        return candidates[0]\n",
    "\n",
    "    p = Path.cwd()\n",
    "    for _ in range(10):\n",
    "        if (p / \"pipeline_config.yaml\").exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    raise FileNotFoundError(\"Could not resolve PROJECT_ROOT. Set HISTO_PROJECT_ROOT env var.\")\n",
    "\n",
    "PROJECT_ROOT = _resolve_project_root()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "\n",
    "# Install deps\n",
    "import subprocess\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", \"-r\", str(PROJECT_ROOT / \"requirements.txt\")])\n",
    "\n",
    "# Optional clustering extras\n",
    "try:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", \"umap-learn\"])\n",
    "except Exception as e:\n",
    "    print(\"⚠️ optional install failed (umap-learn):\", e)\n",
    "\n",
    "try:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", \"hdbscan\"])\n",
    "except Exception as e:\n",
    "    print(\"⚠️ optional install failed (hdbscan):\", e)\n",
    "\n",
    "import yaml\n",
    "cfg = yaml.safe_load((PROJECT_ROOT / \"pipeline_config.yaml\").read_text())\n",
    "\n",
    "EXPORTS_DIR = PROJECT_ROOT / str(cfg.get(\"paths\", {}).get(\"exports_dir\", \"exports\"))\n",
    "EXPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SAFE_MODE = bool(cfg.get(\"project\", {}).get(\"safe_mode\", True))\n",
    "SEED = int(cfg.get(\"project\", {}).get(\"seed\", 1337))\n",
    "\n",
    "print(\"SAFE_MODE:\", SAFE_MODE, \"| EDA_LEVEL:\", EDA_LEVEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea91043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Stage paths + registries ---\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from histo_cartography.viz import ensure_dir, save_and_display, register_plot, display_image\n",
    "from histo_cartography.artifact_registry import register_artifact, append_stage_manifest\n",
    "from histo_cartography.critic import run_critic, write_critic_report, critic_result_table, critic_issues_table\n",
    "\n",
    "stage_in = EXPORTS_DIR / \"stage_02_embeddings\" / \"items_with_embeddings.parquet\"\n",
    "assert stage_in.exists(), f\"missing upstream parquet: {stage_in}\"\n",
    "\n",
    "stage_dir = EXPORTS_DIR / \"stage_03_clustering\"\n",
    "plots_dir = ensure_dir(stage_dir / \"plots\")\n",
    "qa_dir = ensure_dir(stage_dir / \"qa\")\n",
    "eda_dir = ensure_dir(stage_dir / \"eda\")\n",
    "\n",
    "items_with_clusters_path = stage_dir / \"items_with_clusters.parquet\"\n",
    "centroids_path = stage_dir / \"cluster_centroids.parquet\"\n",
    "\n",
    "viz_records = []\n",
    "\n",
    "print(\"stage_in:\", stage_in)\n",
    "print(\"stage_dir:\", stage_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ea53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load upstream parquet (Stage 02) ---\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "items = pd.read_parquet(stage_in)\n",
    "display(items.head(3))\n",
    "print(\"items shape:\", items.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241c7a08",
   "metadata": {},
   "source": [
    "## PEEP — Preflight health + EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03daf412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEEP (1/4) — Overview table\n",
    "from IPython.display import display\n",
    "from histo_cartography.eda_reports import df_overview_table\n",
    "\n",
    "display(df_overview_table(items, max_cols=40).head(40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92529c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEEP (2/4) — Missingness plot\n",
    "from histo_cartography.eda_reports import plot_missingness\n",
    "\n",
    "fig = plot_missingness(items, top_k=25, title=\"Stage 03 PEEP: items_with_embeddings missingness (top 25)\")\n",
    "out_path = plots_dir / \"peep_missingness_top25.png\"\n",
    "save_and_display(fig, out_path)\n",
    "register_plot(viz_records, stage=\"stage_03_clustering\", plot_id=\"peep_missingness_top25\", title=\"PEEP missingness (top 25 columns)\", path=out_path, tags=[\"peep\",\"missingness\"], is_core=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ac4ebf",
   "metadata": {},
   "source": [
    "**Interpretation**: vectors must be present; missing `vector` or `dim` will break clustering.\n",
    "\n",
    "**Warning signs**: Any null vectors, inconsistent `dim`, or NaNs in embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc94f64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEEP (3/4) — Label distribution (bar)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vc = items[\"label\"].astype(str).value_counts().head(30)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "plt.bar(vc.index.astype(str), vc.values)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Stage 03 PEEP: label distribution (top 30)\")\n",
    "plt.ylabel(\"n items\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = plots_dir / \"peep_label_distribution_top30.png\"\n",
    "save_and_display(fig, out_path)\n",
    "register_plot(viz_records, stage=\"stage_03_clustering\", plot_id=\"peep_label_distribution_top30\", title=\"PEEP label distribution (top 30)\", path=out_path, tags=[\"peep\",\"distribution\",\"label\"], is_core=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b791afc5",
   "metadata": {},
   "source": [
    "**Interpretation**: In mixed datasets, labels can be imbalanced; clustering should not just replicate label skew.\n",
    "\n",
    "**Warning signs**: missing labels, or a single label dominating 95%+ of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f4ca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEEP (4/4) — Critic gates (items_with_embeddings)\n",
    "from IPython.display import display\n",
    "\n",
    "critic_in = run_critic(\n",
    "    df=items,\n",
    "    stage=\"stage_03_clustering\",\n",
    "    gate=\"peep_items_with_embeddings\",\n",
    "    required_cols=[\"item_id\",\"source\",\"label\",\"image_path\",\"vector\",\"dim\"],\n",
    "    id_col=\"item_id\",\n",
    "    min_rows=100 if not SAFE_MODE else 10,\n",
    "    key_nonnull_cols=[\"item_id\",\"image_path\",\"vector\"],\n",
    "    vector_col=\"vector\",\n",
    "    finite_cols=[],\n",
    ")\n",
    "\n",
    "write_critic_report(critic_in, qa_dir / \"critic_peep_items_with_embeddings.json\")\n",
    "display(critic_result_table(critic_in))\n",
    "display(critic_issues_table(critic_in).head(50))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a44b63",
   "metadata": {},
   "source": [
    "## Stage logic — Clustering (idempotent)\n",
    "Default: UMAP → HDBSCAN parameter sweep. Falls back to KMeans if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168fdb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main stage logic ---\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from histo_cartography.exports import save_parquet\n",
    "from histo_cartography import clustering as clus\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "if items_with_clusters_path.exists() and centroids_path.exists() and not FORCE_REBUILD:\n",
    "    items_with_clusters = pd.read_parquet(items_with_clusters_path)\n",
    "    cluster_centroids = pd.read_parquet(centroids_path)\n",
    "    print(f\"✅ Loaded existing clustering outputs: items={items_with_clusters.shape}, centroids={cluster_centroids.shape}\")\n",
    "else:\n",
    "    fused = items[[\"item_id\", \"vector\"]].copy()\n",
    "    labels = items[\"label\"].astype(str)\n",
    "\n",
    "    cart_cfg = cfg.get(\"cartography\", {})\n",
    "    sweep_cfg = cart_cfg.get(\"clustering_sweep\", {})\n",
    "\n",
    "    def _safe_seq(x, fallback):\n",
    "        if isinstance(x, list) and len(x) > 0:\n",
    "            return x\n",
    "        return fallback\n",
    "\n",
    "    if SAFE_MODE:\n",
    "        umap_n_neighbors = [int(cart_cfg.get(\"umap\", {}).get(\"n_neighbors\", 15))]\n",
    "        umap_min_dist = [float(cart_cfg.get(\"umap\", {}).get(\"min_dist\", 0.1))]\n",
    "        hdbscan_mcs = [int(cart_cfg.get(\"hdbscan\", {}).get(\"min_cluster_size\", 8))]\n",
    "        hdbscan_ms = [None]\n",
    "    else:\n",
    "        umap_n_neighbors = [int(v) for v in _safe_seq(sweep_cfg.get(\"umap_n_neighbors\"), [10, 20, 50])]\n",
    "        umap_min_dist = [float(v) for v in _safe_seq(sweep_cfg.get(\"umap_min_dist\"), [0.0, 0.1, 0.3])]\n",
    "        hdbscan_mcs = [int(v) for v in _safe_seq(sweep_cfg.get(\"hdbscan_min_cluster_size\"), [5, 8, 10, 15])]\n",
    "        hdbscan_ms = [None if v is None else int(v) for v in _safe_seq(sweep_cfg.get(\"hdbscan_min_samples\"), [None, 5, 10])]\n",
    "\n",
    "    out_sweep_dir = stage_dir / \"hdbscan_sweep\"\n",
    "    results_df, best_run, best_clusters_df = clus.hdbscan_parameter_sweep(\n",
    "        fused=fused,\n",
    "        labels=labels,\n",
    "        out_dir=out_sweep_dir,\n",
    "        umap_n_neighbors=umap_n_neighbors,\n",
    "        umap_min_dist=umap_min_dist,\n",
    "        hdbscan_min_cluster_size=hdbscan_mcs,\n",
    "        hdbscan_min_samples=hdbscan_ms,\n",
    "        random_state=SEED,\n",
    "        make_plots=not SAFE_MODE,  # sweep plots can be heavy; core plots are generated below\n",
    "        max_noise_ratio=float(cart_cfg.get(\"clustering\", {}).get(\"best_run\", {}).get(\"max_noise_ratio\", 0.40)),\n",
    "    )\n",
    "\n",
    "    if best_clusters_df is not None:\n",
    "        clusters_df = best_clusters_df.copy()\n",
    "        (stage_dir / \"best_run.json\").write_text(json.dumps(best_run, indent=2) if best_run is not None else \"{}\")\n",
    "        print(\"✅ Using best HDBSCAN run:\", best_run.get(\"run_name\") if best_run else None)\n",
    "    else:\n",
    "        k = int(cart_cfg.get(\"kmeans\", {}).get(\"k\", 9))\n",
    "        y_pred, meta = clus.run_kmeans(clus._to_matrix(fused), k=k, random_state=SEED)\n",
    "        clusters_df = pd.DataFrame({\"item_id\": fused[\"item_id\"].tolist(), \"cluster_id\": y_pred.tolist()})\n",
    "        (stage_dir / \"kmeans_meta.json\").write_text(json.dumps(meta, indent=2))\n",
    "        print(\"✅ Using KMeans fallback: k=\", k)\n",
    "\n",
    "    # 2D coords for cartography (UMAP preferred; PCA fallback inside compute_umap)\n",
    "    X = clus._to_matrix(fused)\n",
    "    coords2d, meta2d = clus.compute_umap(\n",
    "        X,\n",
    "        n_neighbors=int(cart_cfg.get(\"umap\", {}).get(\"n_neighbors\", 15)),\n",
    "        min_dist=float(cart_cfg.get(\"umap\", {}).get(\"min_dist\", 0.1)),\n",
    "        n_components=2,\n",
    "        metric=\"cosine\",\n",
    "        random_state=SEED,\n",
    "    )\n",
    "    coords_df = pd.DataFrame({\"item_id\": fused[\"item_id\"].tolist(), \"x\": coords2d[:, 0], \"y\": coords2d[:, 1]})\n",
    "    (stage_dir / \"cartography_2d_meta.json\").write_text(json.dumps(meta2d, indent=2))\n",
    "\n",
    "    # Merge\n",
    "    items_with_clusters = items.merge(clusters_df, on=\"item_id\", how=\"left\").merge(coords_df, on=\"item_id\", how=\"left\")\n",
    "    assert items_with_clusters[\"cluster_id\"].isna().sum() == 0, \"missing cluster_id assignments\"\n",
    "\n",
    "    # Centroids (exclude noise cluster -1 only for summaries; still compute it here for evidence)\n",
    "    rows = []\n",
    "    for cid, g in items_with_clusters.groupby(\"cluster_id\"):\n",
    "        cid = int(cid)\n",
    "        vecs = np.asarray(g[\"vector\"].tolist(), dtype=np.float32)\n",
    "        centroid = vecs.mean(axis=0).astype(np.float32)\n",
    "        rows.append({\"cluster_id\": cid, \"n_items\": int(len(g)), \"vector\": centroid.tolist()})\n",
    "    cluster_centroids = pd.DataFrame(rows).sort_values(\"cluster_id\").reset_index(drop=True)\n",
    "\n",
    "    save_parquet(items_with_clusters, items_with_clusters_path)\n",
    "    save_parquet(cluster_centroids, centroids_path)\n",
    "\n",
    "runtime_sec = time.time() - t0\n",
    "print(\"runtime_sec:\", round(runtime_sec, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa145a4",
   "metadata": {},
   "source": [
    "## CHECKPOINT — After clustering + cartography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a063902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKPOINT: critic on items_with_clusters (cluster_id + coords must be finite)\n",
    "from IPython.display import display\n",
    "\n",
    "critic_clusters = run_critic(\n",
    "    df=items_with_clusters,\n",
    "    stage=\"stage_03_clustering\",\n",
    "    gate=\"checkpoint_items_with_clusters\",\n",
    "    required_cols=[\"item_id\",\"cluster_id\",\"x\",\"y\",\"vector\",\"image_path\",\"label\",\"source\"],\n",
    "    id_col=\"item_id\",\n",
    "    min_rows=100 if not SAFE_MODE else 10,\n",
    "    key_nonnull_cols=[\"item_id\",\"cluster_id\",\"x\",\"y\"],\n",
    "    vector_col=\"vector\",\n",
    "    finite_cols=[\"x\",\"y\"],\n",
    ")\n",
    "\n",
    "write_critic_report(critic_clusters, qa_dir / \"critic_checkpoint_items_with_clusters.json\")\n",
    "display(critic_result_table(critic_clusters))\n",
    "display(critic_issues_table(critic_clusters).head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268980a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register artifacts + stage manifest\n",
    "schema_version = str(cfg.get(\"project\", {}).get(\"schema_version\", \"0.1.0\"))\n",
    "\n",
    "register_artifact(\n",
    "    project_root=PROJECT_ROOT,\n",
    "    stage=\"stage_03_clustering\",\n",
    "    artifact=\"items_with_clusters\",\n",
    "    path=items_with_clusters_path,\n",
    "    schema_version=schema_version,\n",
    "    inputs=[stage_in],\n",
    "    df=items_with_clusters,\n",
    "    warnings_count=int(critic_clusters.warnings_count),\n",
    "    fails_count=int(critic_clusters.fails_count),\n",
    "    runtime_sec=float(runtime_sec),\n",
    "    notes=\"items + cluster assignments + 2d coords\",\n",
    ")\n",
    "register_artifact(\n",
    "    project_root=PROJECT_ROOT,\n",
    "    stage=\"stage_03_clustering\",\n",
    "    artifact=\"cluster_centroids\",\n",
    "    path=centroids_path,\n",
    "    schema_version=schema_version,\n",
    "    inputs=[stage_in],\n",
    "    df=cluster_centroids,\n",
    "    warnings_count=int(critic_clusters.warnings_count),\n",
    "    fails_count=int(critic_clusters.fails_count),\n",
    "    runtime_sec=float(runtime_sec),\n",
    "    notes=\"cluster centroids (mean vector)\",\n",
    ")\n",
    "\n",
    "append_stage_manifest(\n",
    "    project_root=PROJECT_ROOT,\n",
    "    stage=\"stage_03_clustering\",\n",
    "    inputs=[stage_in],\n",
    "    outputs=[items_with_clusters_path, centroids_path],\n",
    "    schema_version=schema_version,\n",
    "    warnings_count=int(critic_clusters.warnings_count),\n",
    "    fails_count=int(critic_clusters.fails_count),\n",
    "    runtime_sec=float(runtime_sec),\n",
    "    notes=\"stage 03 run summary\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf94424b",
   "metadata": {},
   "source": [
    "## POST — Postflight health + EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d43fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST (1/3) — Overview table (items_with_clusters)\n",
    "from IPython.display import display\n",
    "from histo_cartography.eda_reports import df_overview_table\n",
    "\n",
    "display(df_overview_table(items_with_clusters, max_cols=45).head(45))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e1a435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST (2/3) — Missingness plot (items_with_clusters)\n",
    "from histo_cartography.eda_reports import plot_missingness\n",
    "\n",
    "fig = plot_missingness(items_with_clusters, top_k=25, title=\"Stage 03 POST: items_with_clusters missingness (top 25)\")\n",
    "out_path = plots_dir / \"post_missingness_top25.png\"\n",
    "save_and_display(fig, out_path)\n",
    "register_plot(viz_records, stage=\"stage_03_clustering\", plot_id=\"post_missingness_top25\", title=\"POST missingness (top 25 columns)\", path=out_path, tags=[\"post\",\"missingness\"], is_core=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a775ab9",
   "metadata": {},
   "source": [
    "**Interpretation**: `cluster_id`, `x`, `y` should be complete for all items.\n",
    "\n",
    "**Warning signs**: missing coords indicate dimensionality reduction failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e6c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST (3/3) — Critic summary\n",
    "from IPython.display import display\n",
    "\n",
    "display(critic_result_table(critic_clusters))\n",
    "display(critic_issues_table(critic_clusters).head(50))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0140f83",
   "metadata": {},
   "source": [
    "## Core clustering/cartography diagnostics (one plot per cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4723ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Core plot 1 — Cluster size distribution (excluding -1)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vc = items_with_clusters[\"cluster_id\"].astype(int).value_counts()\n",
    "vc_no_noise = vc[vc.index != -1]\n",
    "\n",
    "fig = plt.figure(figsize=(7, 4))\n",
    "plt.hist(vc_no_noise.values, bins=min(30, max(5, len(vc_no_noise))), edgecolor=\"black\")\n",
    "plt.title(\"Cluster size distribution (excluding -1)\")\n",
    "plt.xlabel(\"cluster size\")\n",
    "plt.ylabel(\"count of clusters\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = plots_dir / \"cluster_size_hist_excluding_noise.png\"\n",
    "save_and_display(fig, out_path)\n",
    "register_plot(viz_records, stage=\"stage_03_clustering\", plot_id=\"cluster_size_hist_excluding_noise\", title=\"Cluster size distribution (excluding -1)\", path=out_path, tags=[\"core\",\"clustering\"], is_core=True)\n",
    "\n",
    "# gini coefficient (imbalance diagnostic)\n",
    "x = vc_no_noise.values.astype(float)\n",
    "x = np.sort(x)\n",
    "n = len(x)\n",
    "gini = float((2*np.arange(1,n+1)-n-1).dot(x) / (n*x.sum() + 1e-12)) if n>0 else None\n",
    "(qa_dir / \"cluster_size_gini.json\").write_text(json.dumps({\"gini\": gini}, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd05cea",
   "metadata": {},
   "source": [
    "**Interpretation**: Healthy clustering has a mix of sizes; extreme imbalance can indicate overly aggressive clustering.\n",
    "\n",
    "**Warning signs**: Many tiny clusters or one giant cluster; very high Gini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5dffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core plot 2 — Top 30 clusters by size (excluding -1)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "top = vc_no_noise.head(30)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "plt.bar(top.index.astype(str), top.values)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Top 30 clusters by size (excluding -1)\")\n",
    "plt.ylabel(\"n items\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = plots_dir / \"cluster_sizes_top30.png\"\n",
    "save_and_display(fig, out_path)\n",
    "register_plot(viz_records, stage=\"stage_03_clustering\", plot_id=\"cluster_sizes_top30\", title=\"Top 30 clusters by size\", path=out_path, tags=[\"core\",\"clustering\"], is_core=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0021a1c7",
   "metadata": {},
   "source": [
    "**Interpretation**: Large clusters often dominate semantics; consider reviewing them first.\n",
    "\n",
    "**Warning signs**: One cluster dwarfs all others; may need different HDBSCAN settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c46882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core plot 3 — 2D map colored by tissue label\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = items_with_clusters.copy()\n",
    "df[\"label_str\"] = df[\"label\"].astype(str)\n",
    "\n",
    "fig = plt.figure(figsize=(7, 6))\n",
    "for lab, g in df.groupby(\"label_str\"):\n",
    "    plt.scatter(g[\"x\"], g[\"y\"], s=8, alpha=0.6, label=str(lab))\n",
    "plt.legend(markerscale=2, bbox_to_anchor=(1.05, 1), loc=\"upper left\", fontsize=7)\n",
    "plt.title(\"2D map colored by tissue label\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = plots_dir / \"map2d_by_label.png\"\n",
    "save_and_display(fig, out_path)\n",
    "register_plot(viz_records, stage=\"stage_03_clustering\", plot_id=\"map2d_by_label\", title=\"2D map colored by tissue label\", path=out_path, tags=[\"core\",\"cartography\",\"label\"], is_core=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1434a2",
   "metadata": {},
   "source": [
    "**Interpretation**: Labels should show local coherence, not necessarily perfect separation.\n",
    "\n",
    "**Warning signs**: Completely mixed labels everywhere (no structure) or perfect separation (possible leakage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc20d3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core plot 4 — 2D map colored by cluster_id (proxy for “named clusters”)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = items_with_clusters.copy()\n",
    "df[\"cluster_str\"] = df[\"cluster_id\"].astype(int).astype(str)\n",
    "\n",
    "fig = plt.figure(figsize=(7, 6))\n",
    "for cid, g in df.groupby(\"cluster_str\"):\n",
    "    # skip too many clusters in legend\n",
    "    if len(df[\"cluster_str\"].unique()) > 30:\n",
    "        break\n",
    "    plt.scatter(g[\"x\"], g[\"y\"], s=8, alpha=0.6, label=str(cid))\n",
    "plt.legend(markerscale=2, bbox_to_anchor=(1.05, 1), loc=\"upper left\", fontsize=7)\n",
    "plt.title(\"2D map colored by cluster_id\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = plots_dir / \"map2d_by_cluster.png\"\n",
    "save_and_display(fig, out_path)\n",
    "register_plot(viz_records, stage=\"stage_03_clustering\", plot_id=\"map2d_by_cluster\", title=\"2D map colored by cluster_id\", path=out_path, tags=[\"core\",\"cartography\",\"cluster\"], is_core=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff269108",
   "metadata": {},
   "source": [
    "**Interpretation**: Clusters should correspond to coherent regions in the map.\n",
    "\n",
    "**Warning signs**: Clusters are spatially scattered everywhere (unstable clustering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded9ce0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core plot 5 — Cluster × Label composition heatmap (row-normalized, top clusters)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# focus on largest clusters for readability\n",
    "top_clusters = vc_no_noise.head(15).index.tolist()\n",
    "sub = items_with_clusters[items_with_clusters[\"cluster_id\"].astype(int).isin(top_clusters)].copy()\n",
    "\n",
    "ct = pd.crosstab(sub[\"cluster_id\"].astype(int), sub[\"label\"].astype(str))\n",
    "ctn = ct.div(ct.sum(axis=1), axis=0)\n",
    "\n",
    "fig = plt.figure(figsize=(max(8, 0.6 * len(ctn.columns)), max(4, 0.3 * len(ctn.index))))\n",
    "plt.imshow(ctn.values, aspect=\"auto\")\n",
    "plt.colorbar(label=\"fraction within cluster\")\n",
    "plt.xticks(range(len(ctn.columns)), ctn.columns.tolist(), rotation=45, ha=\"right\")\n",
    "plt.yticks(range(len(ctn.index)), [str(x) for x in ctn.index.tolist()])\n",
    "plt.title(\"Cluster × Label composition (row-normalized, top clusters)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = plots_dir / \"cluster_label_heatmap_top.png\"\n",
    "save_and_display(fig, out_path)\n",
    "register_plot(viz_records, stage=\"stage_03_clustering\", plot_id=\"cluster_label_heatmap_top\", title=\"Cluster × Label composition heatmap (top clusters)\", path=out_path, tags=[\"core\",\"clustering\",\"purity\"], is_core=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3edaff7",
   "metadata": {},
   "source": [
    "**Interpretation**: Pure clusters (one dominant label) can be easier to name; mixed clusters may represent transitions or confounds.\n",
    "\n",
    "**Warning signs**: Large clusters that are highly mixed may need higher embedding quality or different clustering resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae45f70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core plot 6 — Cluster label purity distribution (excluding -1, top clusters)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "purity = []\n",
    "for cid, g in items_with_clusters.groupby(items_with_clusters[\"cluster_id\"].astype(int)):\n",
    "    if int(cid) == -1:\n",
    "        continue\n",
    "    vc = g[\"label\"].astype(str).value_counts()\n",
    "    if len(vc)==0:\n",
    "        continue\n",
    "    purity.append(float(vc.iloc[0] / len(g)))\n",
    "\n",
    "fig = plt.figure(figsize=(7, 4))\n",
    "plt.hist(purity, bins=20, edgecolor=\"black\")\n",
    "plt.title(\"Cluster label purity distribution (excluding -1)\")\n",
    "plt.xlabel(\"purity (majority label fraction)\")\n",
    "plt.ylabel(\"count of clusters\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = plots_dir / \"cluster_label_purity_hist.png\"\n",
    "save_and_display(fig, out_path)\n",
    "register_plot(viz_records, stage=\"stage_03_clustering\", plot_id=\"cluster_label_purity_hist\", title=\"Cluster label purity distribution (excluding -1)\", path=out_path, tags=[\"core\",\"clustering\",\"purity\"], is_core=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d660a881",
   "metadata": {},
   "source": [
    "**Interpretation**: Purity is a diagnostic, not a target. Mixed clusters can be valid.\n",
    "\n",
    "**Warning signs**: Very low purity across most clusters may indicate embeddings not capturing tissue signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e52d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core diagnostic 7 — Silhouette score distribution on a sample (optional)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import silhouette_samples\n",
    "\n",
    "# sample for speed\n",
    "n = min(len(items_with_clusters), 2000 if FAST_MODE else 8000)\n",
    "idx = np.random.default_rng(SEED).choice(len(items_with_clusters), size=n, replace=False)\n",
    "\n",
    "X = np.asarray(items_with_clusters.iloc[idx][\"vector\"].tolist(), dtype=np.float32)\n",
    "y = items_with_clusters.iloc[idx][\"cluster_id\"].astype(int).to_numpy()\n",
    "\n",
    "# silhouette requires >1 cluster and no singletons\n",
    "if len(set(y)) > 1 and (pd.Series(y).value_counts().min() >= 2):\n",
    "    sil = silhouette_samples(X, y, metric=\"cosine\")\n",
    "    fig = plt.figure(figsize=(7, 4))\n",
    "    plt.hist(sil, bins=30, edgecolor=\"black\")\n",
    "    plt.title(\"Silhouette distribution (sampled, cosine)\")\n",
    "    plt.xlabel(\"silhouette\")\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.tight_layout()\n",
    "else:\n",
    "    fig = plt.figure(figsize=(7, 4))\n",
    "    plt.title(\"Silhouette distribution (not enough clusters / singletons)\")\n",
    "\n",
    "out_path = plots_dir / \"silhouette_hist_sampled.png\"\n",
    "save_and_display(fig, out_path)\n",
    "register_plot(viz_records, stage=\"stage_03_clustering\", plot_id=\"silhouette_hist_sampled\", title=\"Silhouette distribution (sampled)\", path=out_path, tags=[\"core\",\"clustering\",\"silhouette\"], is_core=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e0e1e9",
   "metadata": {},
   "source": [
    "**Interpretation**: Silhouette > 0 indicates separation, < 0 indicates overlap.\n",
    "\n",
    "**Warning signs**: Most values near 0 or negative might mean clusters are not well-separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f1785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose clusters for representative montages (core)\n",
    "# We prioritize largest non-noise clusters.\n",
    "core_cluster_ids = [int(x) for x in vc_no_noise.head(3).index.tolist()]\n",
    "flagged_cluster_ids = [int(x) for x in vc_no_noise.tail(3).index.tolist()]  # smallest clusters (diagnostic)\n",
    "print(\"core_cluster_ids:\", core_cluster_ids)\n",
    "print(\"flagged_cluster_ids:\", flagged_cluster_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d954152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core plot montage — Representative images for core_cluster_ids[0] (if available)\n",
    "from histo_cartography.image_viz import montage_by_cluster\n",
    "\n",
    "if len(core_cluster_ids) > 0:\n",
    "    cid = core_cluster_ids[0]\n",
    "    out_path = plots_dir / f\"montage_cluster_{cid}.png\"\n",
    "    montage_by_cluster(items_with_clusters, cluster_id=cid, out_path=out_path, image_col=\"image_path\", n=36, random_state=SEED)\n",
    "    display_image(out_path)\n",
    "    register_plot(viz_records, stage=\"stage_03_clustering\", plot_id=f\"montage_cluster_{cid}\", title=f\"Representative montage: cluster {cid}\", path=out_path, tags=[\"core\",\"montage\",\"cluster\"], is_core=True)\n",
    "else:\n",
    "    print(\"not enough clusters for montage\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8b7116",
   "metadata": {},
   "source": [
    "**Interpretation**: Montages are the most important “glass box” evidence for cluster coherence.\n",
    "\n",
    "**Warning signs**: Mixed morphologies within a single cluster; obvious artifacts; blank/failed image loads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244bd961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core plot montage — Representative images for core_cluster_ids[1] (if available)\n",
    "from histo_cartography.image_viz import montage_by_cluster\n",
    "\n",
    "if len(core_cluster_ids) > 1:\n",
    "    cid = core_cluster_ids[1]\n",
    "    out_path = plots_dir / f\"montage_cluster_{cid}.png\"\n",
    "    montage_by_cluster(items_with_clusters, cluster_id=cid, out_path=out_path, image_col=\"image_path\", n=36, random_state=SEED)\n",
    "    display_image(out_path)\n",
    "    register_plot(viz_records, stage=\"stage_03_clustering\", plot_id=f\"montage_cluster_{cid}\", title=f\"Representative montage: cluster {cid}\", path=out_path, tags=[\"core\",\"montage\",\"cluster\"], is_core=True)\n",
    "else:\n",
    "    print(\"not enough clusters for montage\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baad99f",
   "metadata": {},
   "source": [
    "**Interpretation**: Montages are the most important “glass box” evidence for cluster coherence.\n",
    "\n",
    "**Warning signs**: Mixed morphologies within a single cluster; obvious artifacts; blank/failed image loads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc566466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core plot montage — Representative images for core_cluster_ids[2] (if available)\n",
    "from histo_cartography.image_viz import montage_by_cluster\n",
    "\n",
    "if len(core_cluster_ids) > 2:\n",
    "    cid = core_cluster_ids[2]\n",
    "    out_path = plots_dir / f\"montage_cluster_{cid}.png\"\n",
    "    montage_by_cluster(items_with_clusters, cluster_id=cid, out_path=out_path, image_col=\"image_path\", n=36, random_state=SEED)\n",
    "    display_image(out_path)\n",
    "    register_plot(viz_records, stage=\"stage_03_clustering\", plot_id=f\"montage_cluster_{cid}\", title=f\"Representative montage: cluster {cid}\", path=out_path, tags=[\"core\",\"montage\",\"cluster\"], is_core=True)\n",
    "else:\n",
    "    print(\"not enough clusters for montage\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fc5f5d",
   "metadata": {},
   "source": [
    "**Interpretation**: Montages are the most important “glass box” evidence for cluster coherence.\n",
    "\n",
    "**Warning signs**: Mixed morphologies within a single cluster; obvious artifacts; blank/failed image loads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c55b8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic montage — Representative images for flagged_cluster_ids[0] (small/tail clusters)\n",
    "from histo_cartography.image_viz import montage_by_cluster\n",
    "\n",
    "if len(flagged_cluster_ids) > 0:\n",
    "    cid = flagged_cluster_ids[0]\n",
    "    out_path = plots_dir / f\"montage_flagged_cluster_{cid}.png\"\n",
    "    montage_by_cluster(items_with_clusters, cluster_id=cid, out_path=out_path, image_col=\"image_path\", n=36, random_state=SEED)\n",
    "    display_image(out_path)\n",
    "    register_plot(viz_records, stage=\"stage_03_clustering\", plot_id=f\"montage_flagged_cluster_{cid}\", title=f\"Flagged montage: cluster {cid}\", path=out_path, tags=[\"diagnostic\",\"montage\",\"cluster\",\"flagged\"], is_core=True)\n",
    "else:\n",
    "    print(\"not enough clusters for montage\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a5ac72",
   "metadata": {},
   "source": [
    "**Interpretation**: Tail clusters are often noise/outliers; review before agentic naming.\n",
    "\n",
    "**Warning signs**: Many tiny clusters → consider increasing min_cluster_size or improving embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049e0289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic montage — Representative images for flagged_cluster_ids[1] (small/tail clusters)\n",
    "from histo_cartography.image_viz import montage_by_cluster\n",
    "\n",
    "if len(flagged_cluster_ids) > 1:\n",
    "    cid = flagged_cluster_ids[1]\n",
    "    out_path = plots_dir / f\"montage_flagged_cluster_{cid}.png\"\n",
    "    montage_by_cluster(items_with_clusters, cluster_id=cid, out_path=out_path, image_col=\"image_path\", n=36, random_state=SEED)\n",
    "    display_image(out_path)\n",
    "    register_plot(viz_records, stage=\"stage_03_clustering\", plot_id=f\"montage_flagged_cluster_{cid}\", title=f\"Flagged montage: cluster {cid}\", path=out_path, tags=[\"diagnostic\",\"montage\",\"cluster\",\"flagged\"], is_core=True)\n",
    "else:\n",
    "    print(\"not enough clusters for montage\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e541eb4",
   "metadata": {},
   "source": [
    "**Interpretation**: Tail clusters are often noise/outliers; review before agentic naming.\n",
    "\n",
    "**Warning signs**: Many tiny clusters → consider increasing min_cluster_size or improving embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0857097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write viz index (parquet + csv) + show preview\n",
    "from IPython.display import display\n",
    "from histo_cartography.viz import write_viz_index, viz_records_to_df\n",
    "\n",
    "viz_index_path = stage_dir / \"viz_index.parquet\"\n",
    "write_viz_index(viz_records, out_parquet=viz_index_path, out_csv=stage_dir / \"viz_index.csv\")\n",
    "\n",
    "viz_df = viz_records_to_df(viz_records)\n",
    "display(viz_df.head(80))\n",
    "print(\"✅ wrote viz_index:\", viz_index_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184047af",
   "metadata": {},
   "source": [
    "## Next actions\n",
    "- If montages look incoherent: revisit Stage 02 (embeddings) or adjust HDBSCAN sweep.\n",
    "- If cluster purity is too low for your use-case: try different fusion strategy or clustering parameters.\n",
    "- Proceed to Stage 04 for **agentic semantic enrichment** (Agent 1)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
